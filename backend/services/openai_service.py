"""
Service d'intÃ©gration OpenAI GPT
GÃ©nÃ©ration de questions adaptatives et planification de projets
Avec retry automatique et gestion d'erreurs robuste
"""
import json
import logging
from openai import OpenAI
from typing import Dict, Any, Optional, List
from config import settings
from models.learning import Question, QuestionOption
import uuid
from datetime import datetime
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type,
    before_sleep_log
)
import openai

# Configuration du logger
logger = logging.getLogger(__name__)
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)


class OpenAIService:
    """Service pour interagir avec OpenAI GPT avec retry automatique"""
    
    def __init__(self):
        """Initialise le service OpenAI"""
        self.client = OpenAI(api_key=settings.OPENAI_API_KEY)
        self.model = "gpt-4o-mini"  # ModÃ¨le rapide et Ã©conomique
        logger.info(f"âœ… OpenAI Service initialisÃ© avec modÃ¨le: {self.model}")
    
    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=2, min=2, max=10),
        retry=retry_if_exception_type((
            openai.APIError,
            openai.APIConnectionError,
            openai.RateLimitError,
            openai.APITimeoutError
        )),
        before_sleep=before_sleep_log(logger, logging.WARNING)
    )
    def generate_content(self, prompt: str, timeout: int = 45) -> str:
        """
        GÃ©nÃ¨re du contenu via GPT avec retry automatique
        
        Args:
            prompt: Le prompt Ã  envoyer
            timeout: Timeout en secondes (default: 45s)
            
        Returns:
            RÃ©ponse gÃ©nÃ©rÃ©e par GPT
            
        Raises:
            openai.APIError: Erreur API aprÃ¨s 3 tentatives
            openai.RateLimitError: Rate limit atteint
            openai.APITimeoutError: Timeout aprÃ¨s 3 tentatives
        """
        try:
            logger.info(f"ğŸ¤– GÃ©nÃ©ration GPT (tentative, timeout={timeout}s)")
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un expert en planification de tÃ¢ches. Tu gÃ©nÃ¨res des listes de tÃ¢ches ACTIONNABLES pour un gestionnaire de tÃ¢ches. Chaque tÃ¢che doit Ãªtre concrÃ¨te, exÃ©cutable et mesurable. Tu rÃ©ponds UNIQUEMENT en JSON valide, sans commentaires ni explications."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                max_tokens=16000,
                timeout=timeout
            )
            
            content = response.choices[0].message.content
            logger.info(f"âœ… GÃ©nÃ©ration rÃ©ussie ({len(content)} caractÃ¨res)")
            return content
            
        except openai.RateLimitError as e:
            logger.error(f"âš ï¸ Rate limit atteint: {e}")
            raise
        except openai.APITimeoutError as e:
            logger.error(f"â±ï¸ Timeout GPT: {e}")
            raise
        except openai.APIConnectionError as e:
            logger.error(f"ğŸ”Œ Erreur connexion OpenAI: {e}")
            raise
        except Exception as e:
            logger.error(f"âŒ Erreur inattendue: {type(e).__name__}: {e}")
            raise
    
    async def generate_question(
        self,
        topic_name: str,
        difficulty: str,
        mastery_level: int,
        learning_style: Optional[str] = None,
        weak_areas: List[str] = [],
        context: Optional[str] = None
    ) -> Question:
        """
        GÃ©nÃ¨re une question adaptÃ©e via GPT
        """
        prompt = self._build_adaptive_prompt(
            topic_name,
            difficulty,
            mastery_level,
            learning_style,
            weak_areas,
            context
        )
        
        try:
            response_text = self.generate_content(prompt)
            question_data = self._parse_response(response_text)
            
            question = Question(
                id=str(uuid.uuid4()),
                topic_id="",
                difficulty=difficulty,
                question_text=question_data["question"],
                question_type="multiple_choice",
                options=[
                    QuestionOption(
                        id=str(uuid.uuid4()),
                        text=opt["text"],
                        is_correct=opt["is_correct"]
                    )
                    for opt in question_data["options"]
                ],
                correct_answer=question_data["correct_answer"],
                explanation=question_data.get("explanation"),
                hints=question_data.get("hints", []),
                generated_at=datetime.now(),
                estimated_time=question_data.get("estimated_time", 60),
                tags=question_data.get("tags", [])
            )
            
            return question
            
        except Exception as e:
            print(f"âŒ Erreur gÃ©nÃ©ration question: {e}")
            return self._create_fallback_question(topic_name, difficulty)
    
    def _build_adaptive_prompt(
        self,
        topic_name: str,
        difficulty: str,
        mastery_level: int,
        learning_style: Optional[str],
        weak_areas: List[str],
        context: Optional[str]
    ) -> str:
        """Construit un prompt adaptatif pour GPT"""
        
        prompt = f"""Tu es un tuteur adaptatif expert en calibration de questions.

PROFIL DE L'APPRENANT:
- Topic: {topic_name}
- Niveau de maÃ®trise: {mastery_level}%
- DifficultÃ© demandÃ©e: {difficulty}
- Style d'apprentissage: {learning_style or "non dÃ©fini"}
- Points faibles: {", ".join(weak_areas) if weak_areas else "aucun"}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
CALIBRAGE DE LA DIFFICULTÃ‰ {difficulty.upper()}
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

{self._get_difficulty_examples(difficulty, mastery_level)}

âš ï¸ CRITÃˆRES STRICTS POUR {difficulty.upper()}:

{"â€¢ Temps: 20-45 secondes maximum" if difficulty == "easy" else ""}
{"â€¢ Une seule Ã©tape de raisonnement" if difficulty == "easy" else ""}
{"â€¢ Vocabulaire simple et direct" if difficulty == "easy" else ""}
{"â€¢ Pas de piÃ¨ges ni de cas limites" if difficulty == "easy" else ""}

{"â€¢ Temps: 45-90 secondes" if difficulty == "medium" else ""}
{"â€¢ 2-3 Ã©tapes de raisonnement" if difficulty == "medium" else ""}
{"â€¢ Combine 2-3 concepts liÃ©s" if difficulty == "medium" else ""}
{"â€¢ Application pratique requise" if difficulty == "medium" else ""}

{"â€¢ Temps: 90-180 secondes" if difficulty == "hard" else ""}
{"â€¢ Analyse multi-niveau" if difficulty == "hard" else ""}
{"â€¢ Synthesis de concepts avancÃ©s" if difficulty == "hard" else ""}
{"â€¢ Demande expertise et rÃ©flexion profonde" if difficulty == "hard" else ""}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

INSTRUCTIONS:
1. GÃ©nÃ¨re UNE question qui matche EXACTEMENT la complexitÃ© des exemples ci-dessus
2. La question doit correspondre au niveau {mastery_level}%
3. Respecte le temps estimÃ© pour {difficulty}
4. Assure-toi que les distracteurs (mauvaises rÃ©ponses) sont plausibles

FORMAT DE RÃ‰PONSE (JSON strict):
{{
    "question": "La question",
    "options": [
        {{"text": "Option A", "is_correct": false}},
        {{"text": "Option B", "is_correct": true}},
        {{"text": "Option C", "is_correct": false}},
        {{"text": "Option D", "is_correct": false}}
    ],
    "correct_answer": "Option B",
    "explanation": "Explication claire et pÃ©dagogique",
    "hints": ["Indice subtil si l'utilisateur bloque"],
    "estimated_time": {30 if difficulty == "easy" else 60 if difficulty == "medium" else 120},
    "tags": ["tag1", "tag2"]
}}

{f"CONTEXTE: {context}" if context else ""}

GÃ©nÃ¨re UNIQUEMENT le JSON."""

        return prompt
    
    def _get_difficulty_description(self, difficulty: str) -> str:
        descriptions = {
            "easy": "Simple, concepts de base",
            "medium": "IntermÃ©diaire, stimulant",
            "hard": "AvancÃ©, demande rÃ©flexion"
        }
        return descriptions.get(difficulty, descriptions["medium"])
    
    def _get_difficulty_examples(self, difficulty: str, mastery_level: int) -> str:
        """GÃ©nÃ¨re des exemples concrets pour calibrer GPT"""
        
        if difficulty == "easy":
            return f"""
EXEMPLES DE QUESTIONS EASY (pour mastery {mastery_level}%):
â€¢ "Qu'est-ce qu'une variable en programmation ?"
  â†’ DÃ©finition simple, concept fondamental
  â†’ Temps estimÃ©: 20-40s
  â†’ RÃ©ponse directe sans piÃ¨ge

â€¢ "Quelle est la diffÃ©rence entre = et == ?"
  â†’ Comparaison basique de deux concepts
  â†’ Une seule opÃ©ration mentale requise
  â†’ Pas de contexte complexe
"""
        
        elif difficulty == "medium":
            return f"""
EXEMPLES DE QUESTIONS MEDIUM (pour mastery {mastery_level}%):
â€¢ "Que va afficher ce code : x = [1,2]; y = x; y.append(3); print(x) ?"
  â†’ NÃ©cessite comprÃ©hension des rÃ©fÃ©rences
  â†’ 2-3 Ã©tapes de raisonnement
  â†’ Temps estimÃ©: 45-90s
  â†’ Combine plusieurs concepts (listes, rÃ©fÃ©rences, mÃ©thodes)

â€¢ "Comment optimiser une boucle qui cherche dans une liste de 10000 Ã©lÃ©ments ?"
  â†’ Application pratique d'un concept
  â†’ NÃ©cessite analyse et choix de solution
"""
        
        else:  # hard
            return f"""
EXEMPLES DE QUESTIONS HARD (pour mastery {mastery_level}%):
â€¢ "Expliquez pourquoi ce code a une complexitÃ© O(nÂ²) et proposez une optimisation O(n)"
  â†’ Analyse de complexitÃ© algorithmique
  â†’ NÃ©cessite comprÃ©hension profonde
  â†’ Temps estimÃ©: 90-180s
  â†’ Synthesis de plusieurs concepts avancÃ©s

â€¢ "Debuggez ce code qui a un memory leak subtil avec les closures"
  â†’ ProblÃ¨me complexe multi-couches
  â†’ Demande expertise et expÃ©rience
"""
    
    def _parse_response(self, response_text: str) -> Dict[str, Any]:
        """Parse la rÃ©ponse JSON de GPT (pour questions)"""
        try:
            clean_text = response_text.strip()
            if clean_text.startswith("```json"):
                clean_text = clean_text[7:]
            if clean_text.startswith("```"):
                clean_text = clean_text[3:]
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3]
            
            data = json.loads(clean_text.strip())
            
            # Validation simple pour les questions
            # Les champs requis dÃ©pendent du contexte (question vs projet)
            # On retourne directement les donnÃ©es parsÃ©es
            return data
            
        except json.JSONDecodeError as e:
            print(f"âŒ Erreur parsing JSON: {e}")
            print(f"RÃ©ponse brute: {response_text[:500]}")
            raise ValueError("RÃ©ponse GPT non valide (JSON malformÃ©)")
    
    def _create_fallback_question(self, topic_name: str, difficulty: str) -> Question:
        """CrÃ©Ã© une question fallback si GPT Ã©choue"""
        return Question(
            id=str(uuid.uuid4()),
            topic_id="",
            difficulty=difficulty,
            question_text=f"Question sur {topic_name} (fallback)",
            question_type="multiple_choice",
            options=[
                QuestionOption(id=str(uuid.uuid4()), text="Option A", is_correct=False),
                QuestionOption(id=str(uuid.uuid4()), text="Option B", is_correct=True),
                QuestionOption(id=str(uuid.uuid4()), text="Option C", is_correct=False),
                QuestionOption(id=str(uuid.uuid4()), text="Option D", is_correct=False),
            ],
            correct_answer="Option B",
            explanation="Question de secours",
            hints=[],
            generated_at=datetime.now()
        )
    
    async def generate_encouragement(
        self,
        is_correct: bool,
        streak: int,
        mastery_change: int
    ) -> str:
        """GÃ©nÃ¨re un message d'encouragement personnalisÃ©"""
        
        prompt = f"""Tu es un coach motivant pour procrastinateurs.

SITUATION:
- RÃ©ponse: {"âœ… CORRECTE" if is_correct else "âŒ Incorrecte"}
- Streak: {streak} jours
- Changement maÃ®trise: {mastery_change:+d} points

GÃ©nÃ¨re un message court (max 2 phrases), positif et Ã©nergique.
RÃ©ponds UNIQUEMENT avec le message, sans JSON, sans formatage."""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "Tu es un coach motivant. RÃ©ponds uniquement avec le message d'encouragement, sans JSON ni formatage."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=100
            )
            message = response.choices[0].message.content.strip()
            # Nettoyer les balises JSON si prÃ©sentes
            if message.startswith("```"):
                message = message.split("```")[1] if "```" in message[3:] else message
            if message.startswith("{") or message.startswith("["):
                # Essayer d'extraire le texte du JSON
                try:
                    import json
                    data = json.loads(message)
                    message = data.get("message", message) if isinstance(data, dict) else message
                except:
                    pass
            return message.strip()
        except:
            if is_correct:
                return f"ğŸ‰ Excellent ! Streak de {streak} jours !" if streak > 0 else "ğŸ‘ Bien jouÃ© !"
            else:
                return "ğŸ’ª Pas grave ! RÃ©essaye !"


# Instance globale
openai_service = OpenAIService()
