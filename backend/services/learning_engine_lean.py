"""
üß† LEARNING ENGINE v4.3 LEAN + AI TUTOR v2.0
Version √©pur√©e avec uniquement les 5 modules ESSENTIELS scientifiquement prouv√©s.
+ Persistance DB pour sauvegarder l'√©tat entre les sessions.
+ v4.2: Quick Wins, Early Game Protection, User Performance Level
+ v4.3: AI Tutor v2.0 - M√©moire cross-session, d√©tection patterns, pr√©diction

Modules conserv√©s:
1. FSRS - Spaced Repetition (Pimsleur, √©tat de l'art)
2. Testing Effect - Quiz actif (Dunlosky 2013, technique #1)
3. Adaptive Difficulty - Zone proximale de d√©veloppement (Vygotsky)
4. Cognitive Load Detection - D√©tection fatigue (Sweller 1988)
5. Interleaving - M√©lange des sujets (Rohrer 2007)

AI Tutor v2.0 Features:
- M√©moire cross-session (l'IA se souvient des sessions pr√©c√©dentes)
- D√©tection de patterns d'erreurs (confusions r√©currentes)
- Motivation adaptative (ton personnalis√© selon tendance)
- Pr√©diction de difficult√© (intervient AVANT l'√©chec)
- Micro-le√ßons cibl√©es (rappels avant questions difficiles)
- Apprentissage cumulatif (meilleure connaissance au fil du temps)

Modules SUPPRIM√âS (redondants ou marginaux):
- Forgetting Curve (doublon FSRS)
- Emotional Encoding (hooks artificiels)
- Dual Coding (pas de vraies images)
- Chunking (contenu d√©j√† d√©coup√©)
- Elaborative Interrogation (GPT fait d√©j√†)
- Pre-sleep (timing impr√©cis)
- Confidence Tracking (gens mentent)
- Transfer Learning (complexe pour peu de gain)
- Variation Practice (doublon interleaving)

Utilisation:
    from services.learning_engine_lean import lean_engine

    # Pour une nouvelle question
    params = lean_engine.get_next_question(user_id, topic_id, mastery)

    # Apr√®s une r√©ponse
    result = lean_engine.process_answer(user_id, topic_id, is_correct, response_time, difficulty)

    # Sauvegarder l'√©tat (automatique apr√®s chaque r√©ponse, ou manuel)
    lean_engine.save_state(user_id)

    # Charger l'√©tat (automatique au d√©marrage)
    lean_engine.load_state(user_id)
"""

import logging
import sqlite3
import json
from datetime import datetime
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from pathlib import Path

# Imports essentiels uniquement
from utils.fsrs_algorithm import FSRS, FSRSCard, Rating
from utils.cognitive_load import CognitiveLoadDetector

logger = logging.getLogger(__name__)

# Chemin de la base de donn√©es
DB_PATH = Path(__file__).parent.parent / "data" / "learning.db"


@dataclass
class QuestionParams:
    """Param√®tres pour la prochaine question"""
    difficulty: int  # 1-5
    difficulty_name: str  # "VERY_EASY" -> "EXPERT"
    topic_id: str
    fsrs_interval: float
    retrievability: float
    cognitive_load: str
    should_take_break: bool
    interleave_suggested: bool  # Sugg√©rer de changer de sujet


@dataclass
class AnswerResult:
    """R√©sultat apr√®s traitement d'une r√©ponse"""
    mastery_change: int
    xp_earned: int
    next_review_days: float
    accuracy_recent: float
    should_reduce_difficulty: bool
    should_take_break: bool
    feedback: str


class LeanLearningEngine:
    """
    Moteur d'apprentissage LEAN v4.1
    5 modules essentiels + persistance DB.
    """

    # Niveaux de difficult√©
    DIFFICULTY_LEVELS = {
        1: {"name": "VERY_EASY", "display": "Tr√®s Facile", "xp": 5, "target_accuracy": 0.90},
        2: {"name": "EASY", "display": "Facile", "xp": 10, "target_accuracy": 0.80},
        3: {"name": "MEDIUM", "display": "Moyen", "xp": 20, "target_accuracy": 0.70},
        4: {"name": "HARD", "display": "Difficile", "xp": 35, "target_accuracy": 0.60},
        5: {"name": "EXPERT", "display": "Expert", "xp": 50, "target_accuracy": 0.50},
    }

    def __init__(self, db_path: str = None):
        # Module 1: FSRS
        self.fsrs = FSRS()

        # √âtat par utilisateur (cache m√©moire)
        self._user_states: Dict[str, Dict[str, Any]] = {}

        # Chemin DB
        self.db_path = db_path or str(DB_PATH)
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)

        # Initialiser la table de persistance
        self._init_db()

        logger.info("üß† Lean Learning Engine v4.3 initialized (5 modules + AI Tutor v2.0)")

    # =========================================================================
    # PERSISTANCE DB
    # =========================================================================

    def _init_db(self):
        """Cr√©e la table de persistance si elle n'existe pas"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS lean_user_states (
                    user_id TEXT PRIMARY KEY,
                    fsrs_cards TEXT,
                    mastery TEXT,
                    streak INTEGER DEFAULT 0,
                    last_topic TEXT,
                    total_xp INTEGER DEFAULT 0,
                    responses_count INTEGER DEFAULT 0,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            conn.commit()
            conn.close()
            logger.info("‚úÖ Table lean_user_states initialis√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur init DB: {e}")

    def _serialize_fsrs_cards(self, cards: Dict[str, FSRSCard]) -> str:
        """S√©rialise les cartes FSRS en JSON"""
        serialized = {}
        for topic_id, card in cards.items():
            serialized[topic_id] = {
                "stability": card.stability,
                "difficulty": card.difficulty,
                "reps": card.reps,
                "lapses": card.lapses,
                "last_review": card.last_review.isoformat() if card.last_review else None
            }
        return json.dumps(serialized)

    def _deserialize_fsrs_cards(self, data: str) -> Dict[str, FSRSCard]:
        """D√©s√©rialise les cartes FSRS depuis JSON"""
        if not data:
            return {}

        try:
            parsed = json.loads(data)
            cards = {}
            for topic_id, card_data in parsed.items():
                card = FSRSCard()
                card.stability = card_data.get("stability", 0)
                card.difficulty = card_data.get("difficulty", 0.3)
                card.reps = card_data.get("reps", 0)
                card.lapses = card_data.get("lapses", 0)
                if card_data.get("last_review"):
                    card.last_review = datetime.fromisoformat(card_data["last_review"])
                cards[topic_id] = card
            return cards
        except Exception as e:
            logger.error(f"Erreur d√©s√©rialisation FSRS: {e}")
            return {}

    def save_state(self, user_id: str) -> bool:
        """Sauvegarde l'√©tat d'un utilisateur en DB"""
        if user_id not in self._user_states:
            return False

        state = self._user_states[user_id]

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT OR REPLACE INTO lean_user_states
                (user_id, fsrs_cards, mastery, streak, last_topic, total_xp, responses_count, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                user_id,
                self._serialize_fsrs_cards(state.get("fsrs_cards", {})),
                json.dumps(state.get("mastery", {})),
                state.get("streak", 0),
                state.get("last_topic"),
                state.get("total_xp", 0),
                len(state.get("responses", [])),
                datetime.now().isoformat()
            ))

            conn.commit()
            conn.close()
            logger.debug(f"‚úÖ √âtat sauvegard√© pour {user_id}")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde √©tat {user_id}: {e}")
            return False

    def load_state(self, user_id: str) -> bool:
        """Charge l'√©tat d'un utilisateur depuis la DB"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM lean_user_states WHERE user_id = ?
            """, (user_id,))

            row = cursor.fetchone()
            conn.close()

            if not row:
                return False

            # Restaurer l'√©tat
            self._user_states[user_id] = {
                "cognitive_detector": CognitiveLoadDetector(),
                "fsrs_cards": self._deserialize_fsrs_cards(row["fsrs_cards"]),
                "responses": [],  # Reset des r√©ponses de session
                "mastery": json.loads(row["mastery"]) if row["mastery"] else {},
                "last_topic": row["last_topic"],
                "streak": row["streak"] or 0,
                "total_xp": row["total_xp"] or 0,
            }

            logger.info(f"‚úÖ √âtat charg√© pour {user_id} (mastery: {len(self._user_states[user_id]['mastery'])} topics)")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur chargement √©tat {user_id}: {e}")
            return False

    def delete_state(self, user_id: str) -> bool:
        """Supprime l'√©tat d'un utilisateur"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("DELETE FROM lean_user_states WHERE user_id = ?", (user_id,))
            conn.commit()
            conn.close()

            if user_id in self._user_states:
                del self._user_states[user_id]

            logger.info(f"‚úÖ √âtat supprim√© pour {user_id}")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur suppression √©tat {user_id}: {e}")
            return False

    def _get_user_state(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re ou cr√©e l'√©tat d'un utilisateur (avec auto-load depuis DB)"""
        if user_id not in self._user_states:
            # Essayer de charger depuis la DB
            if not self.load_state(user_id):
                # Cr√©er un nouvel √©tat
                self._user_states[user_id] = {
                    # Module 4: Cognitive Load
                    "cognitive_detector": CognitiveLoadDetector(),
                    # FSRS cards par topic
                    "fsrs_cards": {},
                    # Historique des r√©ponses pour interleaving et stats
                    "responses": [],
                    # Ma√Ætrise par topic
                    "mastery": {},
                    # Dernier topic (pour interleaving)
                    "last_topic": None,
                    # Streak actuel
                    "streak": 0,
                    # XP total
                    "total_xp": 0,
                }
        return self._user_states[user_id]

    # =========================================================================
    # MODULE 1: FSRS - Spaced Repetition
    # =========================================================================

    def _get_fsrs_card(self, state: Dict, topic_id: str) -> FSRSCard:
        """R√©cup√®re ou cr√©e une carte FSRS"""
        if topic_id not in state["fsrs_cards"]:
            state["fsrs_cards"][topic_id] = FSRSCard()
        return state["fsrs_cards"][topic_id]

    def _update_fsrs(self, state: Dict, topic_id: str, is_correct: bool, response_time: float) -> tuple:
        """Met √† jour FSRS et retourne (new_card, interval)"""
        card = self._get_fsrs_card(state, topic_id)

        # Convertir en rating FSRS
        if is_correct:
            if response_time < 10:
                rating = Rating.EASY
            elif response_time < 30:
                rating = Rating.GOOD
            else:
                rating = Rating.HARD
        else:
            rating = Rating.AGAIN

        new_card, interval = self.fsrs.review(card, rating)
        state["fsrs_cards"][topic_id] = new_card

        return new_card, interval

    def _get_retrievability(self, state: Dict, topic_id: str) -> float:
        """Calcule la probabilit√© de rappel actuelle"""
        card = self._get_fsrs_card(state, topic_id)
        if card.stability <= 0:
            return 1.0

        days_since = 0
        if card.last_review:
            days_since = (datetime.now() - card.last_review).days

        return self.fsrs.retrievability(days_since, card.stability)

    # =========================================================================
    # MODULE 2: TESTING EFFECT (implicite - l'app fait des quiz)
    # =========================================================================
    # Le testing effect est inh√©rent au fait qu'on pose des questions
    # Pas de code sp√©cifique n√©cessaire

    # =========================================================================
    # MODULE 3: ADAPTIVE DIFFICULTY
    # =========================================================================

    def _calculate_optimal_difficulty(
        self,
        mastery: int,
        retrievability: float,
        cognitive_load: str,
        recent_accuracy: float,
        streak: int,
        user_performance_level: float = 0.5  # 0-1, niveau de performance historique
    ) -> int:
        """
        Calcule le niveau de difficult√© optimal (1-5).

        Objectif: Zone Proximale de D√©veloppement (Vygotsky)
        - Pas trop facile (ennui)
        - Pas trop dur (frustration)
        - Juste assez challengeant (flow)

        AM√âLIORATION v4.2: S'adapte au niveau de performance de l'utilisateur.
        Un utilisateur en difficult√© re√ßoit des questions adapt√©es √† SON niveau.
        """
        # Ma√Ætrise effective = mastery pond√©r√© par performance historique
        # Un user struggling (perf=0.4) avec mastery=50 ‚Üí effective=35
        effective_mastery = mastery * (0.7 + user_performance_level * 0.6)

        # Base: difficult√© selon ma√Ætrise EFFECTIVE
        if effective_mastery < 15:
            base_level = 1
        elif effective_mastery < 30:
            base_level = 2
        elif effective_mastery < 50:
            base_level = 3
        elif effective_mastery < 75:
            base_level = 4
        else:
            base_level = 5

        level = base_level

        # Ajustement retrievability: m√©moire faible = r√©vision
        if retrievability < 0.4:
            level = max(1, level - 1)
        elif retrievability > 0.95 and level < 5:
            level += 1

        # Ajustement cognitive load - PLUS AGRESSIF
        if cognitive_load == "overload":
            level = 1  # Force niveau 1, pas de n√©gociation
        elif cognitive_load == "high":
            level = max(1, level - 1)

        # CLEF: Ajustement performance r√©cente (tr√®s sensible)
        # C'est ici qu'on aide les √©l√®ves en difficult√©
        if recent_accuracy < 0.4:
            level = 1  # Struggling = niveau 1, pas de n√©gociation
        elif recent_accuracy < 0.5:
            level = max(1, level - 1)
        elif recent_accuracy > 0.85 and streak >= 3:
            level = min(5, level + 1)

        # Ajustement streak - PLUS R√âACTIF aux erreurs
        if streak <= -4:
            level = 1  # Force facile apr√®s 4 erreurs cons√©cutives
        elif streak <= -2:
            level = max(1, level - 1)
        elif streak >= 4 and level < 5:
            level += 1

        # CHALLENGE MODE for experts: maintain difficulty at high mastery
        # Seulement si l'utilisateur a une bonne performance historique
        if mastery >= 80 and user_performance_level >= 0.6 and cognitive_load == "optimal" and recent_accuracy > 0.7:
            level = max(4, level)  # Minimum difficulty 4 for experts

        return level

    # =========================================================================
    # MODULE 4: COGNITIVE LOAD DETECTION
    # =========================================================================

    def _assess_cognitive_load(self, state: Dict) -> tuple:
        """√âvalue la charge cognitive et retourne (load_level, should_break)"""
        assessment = state["cognitive_detector"].assess()
        return assessment.overall_load, assessment.should_pause

    # =========================================================================
    # USER PERFORMANCE LEVEL (v4.2)
    # =========================================================================

    def _get_user_performance_level(self, state: Dict) -> float:
        """
        Calcule le niveau de performance historique de l'utilisateur (0-1).

        Bas√© sur:
        - Accuracy sur les 20 derni√®res r√©ponses
        - Ratio de r√©cup√©rations (recovery modes)
        - Streak moyen

        Retourne:
        - 0.4 = utilisateur en difficult√© (struggling)
        - 0.5 = utilisateur moyen
        - 0.7 = utilisateur performant
        """
        responses = state.get("responses", [])

        if len(responses) < 5:
            return 0.5  # Pas assez de donn√©es, d√©faut moyen

        # Accuracy sur les 20 derni√®res
        recent = responses[-20:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / len(recent)

        # Compter les recovery modes (s√©quences de 3+ erreurs)
        recovery_count = 0
        consecutive = 0
        for r in responses[-50:]:
            if not r.get("is_correct", True):
                consecutive += 1
                if consecutive == 3:
                    recovery_count += 1
            else:
                consecutive = 0

        # P√©nalit√© pour beaucoup de recovery modes
        recovery_penalty = min(0.2, recovery_count * 0.05)

        # Score final
        performance = accuracy - recovery_penalty
        return max(0.3, min(0.8, performance))

    def _is_early_game(self, state: Dict) -> bool:
        """
        D√©termine si l'utilisateur est en "early game" (d√©but d'apprentissage).

        Les 7 premiers jours sont critiques - on doit √©viter la spirale n√©gative.
        """
        responses = state.get("responses", [])

        # Moins de 50 r√©ponses = early game
        if len(responses) < 50:
            return True

        # V√©rifier la date de premi√®re r√©ponse
        if responses:
            first_response = responses[0].get("timestamp")
            if first_response:
                days_since_start = (datetime.now() - first_response).days
                return days_since_start <= 7

        return False

    # =========================================================================
    # AI TUTOR v2.0 - FONCTIONNALIT√âS AVANC√âES
    # =========================================================================

    def _get_ai_tutor_context(self, state: Dict, topic_id: str) -> Dict[str, Any]:
        """
        Calcule le contexte AI Tutor v2.0 pour personnaliser l'aide.

        Retourne un dict avec:
        - session_count: nombre de sessions (m√©moire cross-session)
        - skill_errors: erreurs sur ce topic (apprentissage des erreurs)
        - confusion_pairs: confusions d√©tect√©es (patterns)
        - motivation_trend: tendance motivation (-1 √† 1)
        - risk_level: niveau de risque d'√©chec (0-4)
        - needs_micro_lesson: si une micro-le√ßon est recommand√©e
        """
        responses = state.get("responses", [])
        ai_state = state.get("ai_tutor_state", {})

        # 1. Session count (m√©moire cross-session)
        session_count = ai_state.get("session_count", 1)

        # 2. Erreurs sur ce topic
        skill_errors = sum(1 for r in responses if r.get("topic_id") == topic_id and not r.get("is_correct", True))

        # 3. Confusion pairs (patterns d'erreurs entre topics)
        confusion_pairs = ai_state.get("confusion_pairs", {})

        # 4. Tendance motivation (bas√©e sur skip patterns des derniers jours)
        motivation_history = ai_state.get("motivation_history", [])
        motivation_trend = 0.0
        if len(motivation_history) >= 10:
            recent = motivation_history[-10:]
            older = motivation_history[-20:-10] if len(motivation_history) >= 20 else motivation_history[:10]
            if older:
                motivation_trend = (sum(recent) / len(recent)) - (sum(older) / len(older))

        # 5. Calculer le risque d'√©chec
        risk_level = 0
        recent_responses = responses[-5:] if responses else []
        recent_accuracy = sum(1 for r in recent_responses if r.get("is_correct", True)) / max(1, len(recent_responses))

        if recent_accuracy < 0.5:
            risk_level += 1
        if skill_errors > 3:
            risk_level += 1
        if state.get("streak", 0) <= -2:
            risk_level += 1

        # Retrievability basse
        card = self._get_fsrs_card(state, topic_id)
        if card.stability < 1:
            risk_level += 1

        # 6. Micro-le√ßon recommand√©e?
        needs_micro_lesson = risk_level >= 3 or (skill_errors > 5 and recent_accuracy < 0.6)

        return {
            "session_count": session_count,
            "skill_errors": skill_errors,
            "confusion_pairs": confusion_pairs,
            "motivation_trend": motivation_trend,
            "risk_level": risk_level,
            "needs_micro_lesson": needs_micro_lesson,
            "total_questions": len(responses),
        }

    def _update_ai_tutor_state(self, state: Dict, topic_id: str, is_correct: bool):
        """Met √† jour l'√©tat AI Tutor apr√®s une r√©ponse."""
        if "ai_tutor_state" not in state:
            state["ai_tutor_state"] = {
                "session_count": 1,
                "confusion_pairs": {},
                "motivation_history": [],
                "last_topics": [],
            }

        ai_state = state["ai_tutor_state"]

        # Tracker le topic
        last_topics = ai_state.get("last_topics", [])
        last_topics.append(topic_id)
        if len(last_topics) > 20:
            last_topics.pop(0)
        ai_state["last_topics"] = last_topics

        # D√©tecter confusions (erreur apr√®s changement de topic)
        if not is_correct and len(last_topics) >= 2:
            prev_topic = last_topics[-2]
            if prev_topic != topic_id:
                pair = tuple(sorted([prev_topic, topic_id]))
                confusion_pairs = ai_state.get("confusion_pairs", {})
                pair_key = f"{pair[0]}|{pair[1]}"
                confusion_pairs[pair_key] = confusion_pairs.get(pair_key, 0) + 1
                ai_state["confusion_pairs"] = confusion_pairs

    def _increment_session_count(self, state: Dict):
        """Incr√©mente le compteur de sessions (appel√© au d√©but de chaque session)."""
        if "ai_tutor_state" not in state:
            state["ai_tutor_state"] = {}
        state["ai_tutor_state"]["session_count"] = state["ai_tutor_state"].get("session_count", 0) + 1

    def get_ai_tutor_hint(self, state: Dict, topic_id: str, difficulty: int) -> Optional[str]:
        """
        G√©n√®re un hint contextuel bas√© sur l'historique.

        Appel√© par le frontend pour afficher une aide personnalis√©e.
        """
        context = self._get_ai_tutor_context(state, topic_id)

        hints = []

        # Hint bas√© sur les erreurs pass√©es
        if context["skill_errors"] > 0:
            hints.append(f"Tu as eu {context['skill_errors']} erreurs sur ce sujet. Prends ton temps!")

        # Hint si haute risque
        if context["risk_level"] >= 3:
            hints.append("Question difficile d√©tect√©e. Relis bien l'√©nonc√© avant de r√©pondre.")

        # Hint si micro-le√ßon recommand√©e
        if context["needs_micro_lesson"]:
            hints.append("Je te recommande de revoir les bases de ce concept avant de continuer.")

        # Hint motivation
        if context["motivation_trend"] < -0.2:
            hints.append("Tu fais du bon travail! Continue comme √ßa.")

        return hints[0] if hints else None

    # =========================================================================
    # MODULE 5: INTERLEAVING
    # =========================================================================

    def _should_interleave(self, state: Dict, current_topic: str) -> bool:
        """
        D√©termine si on devrait sugg√©rer de changer de sujet.

        Interleaving = m√©langer les sujets au lieu de bloquer.
        +43% de r√©tention selon Rohrer & Taylor (2007).
        """
        # Compter les questions cons√©cutives sur le m√™me topic
        consecutive = 0
        for r in reversed(state["responses"][-10:]):
            if r.get("topic_id") == current_topic:
                consecutive += 1
            else:
                break

        # Sugg√©rer interleaving apr√®s 3-5 questions sur le m√™me sujet
        return consecutive >= 4

    # =========================================================================
    # API PRINCIPALE
    # =========================================================================

    def get_next_question(
        self,
        user_id: str,
        topic_id: str,
        current_mastery: int
    ) -> QuestionParams:
        """
        Calcule les param√®tres optimaux pour la prochaine question.

        Args:
            user_id: ID utilisateur
            topic_id: ID du topic
            current_mastery: Ma√Ætrise actuelle (0-100)

        Returns:
            QuestionParams avec difficult√© optimale et m√©tadonn√©es
        """
        state = self._get_user_state(user_id)

        # Mettre √† jour la ma√Ætrise
        state["mastery"][topic_id] = current_mastery

        # 1. Cognitive Load
        cognitive_load, should_break = self._assess_cognitive_load(state)

        # 2. FSRS
        card = self._get_fsrs_card(state, topic_id)
        retrievability = self._get_retrievability(state, topic_id)

        # 3. Stats r√©centes
        recent = state["responses"][-10:]
        recent_accuracy = sum(1 for r in recent if r.get("is_correct", False)) / max(1, len(recent))

        # 4. Difficult√© optimale
        user_performance = self._get_user_performance_level(state)

        # QUICK WINS: Si des quick wins sont en attente, forcer niveau 1
        quick_wins = state.get("quick_wins_remaining", 0)
        if quick_wins > 0:
            difficulty = 1
            state["quick_wins_remaining"] = quick_wins - 1
            logger.debug(f"Quick win mode: {quick_wins - 1} remaining")
        else:
            difficulty = self._calculate_optimal_difficulty(
                mastery=current_mastery,
                retrievability=retrievability,
                cognitive_load=cognitive_load,
                recent_accuracy=recent_accuracy,
                streak=state["streak"],
                user_performance_level=user_performance
            )

        # EARLY GAME PROTECTION: Les nouveaux utilisateurs struggling
        # ne doivent pas recevoir de questions trop difficiles
        if self._is_early_game(state) and user_performance < 0.5:
            difficulty = min(2, difficulty)  # Max niveau 2 en early game pour struggling

        # 5. Interleaving
        interleave = self._should_interleave(state, topic_id)

        return QuestionParams(
            difficulty=difficulty,
            difficulty_name=self.DIFFICULTY_LEVELS[difficulty]["name"],
            topic_id=topic_id,
            fsrs_interval=card.stability,
            retrievability=retrievability,
            cognitive_load=cognitive_load,
            should_take_break=should_break,
            interleave_suggested=interleave
        )

    def process_answer(
        self,
        user_id: str,
        topic_id: str,
        is_correct: bool,
        response_time: float,
        difficulty: int
    ) -> AnswerResult:
        """
        Traite une r√©ponse et met √† jour tous les modules.

        Args:
            user_id: ID utilisateur
            topic_id: ID topic
            is_correct: R√©ponse correcte?
            response_time: Temps de r√©ponse (secondes)
            difficulty: Niveau de difficult√© (1-5)

        Returns:
            AnswerResult avec feedback et mises √† jour
        """
        state = self._get_user_state(user_id)
        difficulty = max(1, min(5, difficulty))  # Clamp 1-5

        # 1. Cognitive Load - enregistrer la r√©ponse
        diff_str = {1: "easy", 2: "easy", 3: "medium", 4: "hard", 5: "hard"}[difficulty]
        state["cognitive_detector"].add_response(
            response_time=int(response_time),
            is_correct=is_correct,
            difficulty=diff_str
        )

        # 2. FSRS - mettre √† jour
        new_card, interval = self._update_fsrs(state, topic_id, is_correct, response_time)

        # 3. Streak
        if is_correct:
            state["streak"] = max(0, state["streak"]) + 1
        else:
            state["streak"] = min(0, state["streak"]) - 1

        # 4. Calculer changement de ma√Ætrise (AJUST√â: √©quilibr√© pour tous les profils)
        # Multiplicateur invers√© pour niveau 1: on veut encourager les √©l√®ves en difficult√©
        level_multiplier = {1: 1.0, 2: 0.9, 3: 1.0, 4: 1.1, 5: 1.2}[difficulty]

        current = state["mastery"].get(topic_id, 0)

        if is_correct:
            # Gains de base (CALIBR√â pour progression r√©aliste)
            # Objectif: ~5% par jour pour √©l√®ve moyen = ~65% en 14 jours
            base_gain = 3  # Ajust√© pour atteindre objectifs r√©alistes
            if response_time < 10:
                base_gain += 1  # Bonus r√©ponse rapide

            mastery_change = int(base_gain * level_multiplier)

            # BONUS mod√©r√© pour d√©butants
            if current < 20:
                mastery_change = int(mastery_change * 1.2)  # +20% au d√©but
            elif current < 35:
                mastery_change = int(mastery_change * 1.1)  # +10%

            # Rendements d√©croissants progressifs
            # Plus on monte, plus c'est difficile de progresser
            if current >= 90:
                mastery_change = max(1, mastery_change // 5)  # Tr√®s dur apr√®s 90%
            elif current >= 80:
                mastery_change = max(1, mastery_change // 4)
            elif current >= 70:
                mastery_change = max(1, mastery_change // 3)
            elif current >= 55:
                mastery_change = max(1, mastery_change // 2)
            elif current >= 45:
                mastery_change = int(mastery_change * 0.75)
        else:
            # Pertes ajust√©es
            base_loss = -2
            if difficulty <= 2:
                base_loss = -3  # Erreur sur facile = perte mod√©r√©e
            elif difficulty >= 4:
                base_loss = -1  # Erreur sur difficile = pardonn√©

            mastery_change = int(base_loss * level_multiplier)

            # Protection pour d√©butants (mais pas totale)
            if current < 20:
                mastery_change = max(-1, mastery_change)  # Petite perte
            elif current < 35:
                mastery_change = max(-2, mastery_change)

            # STRUGGLING USER PROTECTION: Limit mastery loss during bad streaks
            # If already in a bad streak, don't punish further
            if state["streak"] <= -3:
                mastery_change = max(-1, mastery_change)  # Max 1 point loss

        # 5. XP
        xp_earned = self.DIFFICULTY_LEVELS[difficulty]["xp"] if is_correct else 0
        if is_correct and state["streak"] >= 3:
            xp_earned = int(xp_earned * 1.2)  # Bonus streak

        # 6. Enregistrer la r√©ponse
        state["responses"].append({
            "topic_id": topic_id,
            "is_correct": is_correct,
            "response_time": response_time,
            "difficulty": difficulty,
            "timestamp": datetime.now()
        })
        state["last_topic"] = topic_id

        # 6.1 AI Tutor v2.0: Mettre √† jour l'√©tat IA
        self._update_ai_tutor_state(state, topic_id, is_correct)

        # Mettre √† jour ma√Ætrise
        # Cap at 95% - reaching 100% should require sustained mastery over time
        # This keeps experts engaged and prevents "completion" feeling
        MASTERY_CAP = 95
        current = state["mastery"].get(topic_id, 0)
        new_mastery = max(0, min(MASTERY_CAP, current + mastery_change))
        state["mastery"][topic_id] = new_mastery

        # 7. Stats et feedback
        recent = state["responses"][-10:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / max(1, len(recent))

        cognitive_load, should_break = self._assess_cognitive_load(state)
        should_reduce = cognitive_load in ["high", "overload"] or accuracy < 0.5

        # RECOVERY MODE v4.2: Enhanced support with Quick Wins
        # Track consecutive errors for recovery mode activation
        consecutive_errors = 0
        for r in reversed(state["responses"][-5:]):
            if not r.get("is_correct", True):
                consecutive_errors += 1
            else:
                break

        in_recovery_mode = consecutive_errors >= 3 or (accuracy < 0.4 and len(recent) >= 5)

        # QUICK WINS: Quand l'utilisateur est en difficult√©, on lui donne
        # des questions tr√®s faciles pour reconstruire sa confiance
        # Le nombre d√©pend de sa performance historique
        if in_recovery_mode:
            user_perf = self._get_user_performance_level(state)
            state["quick_wins_remaining"] = 5 if user_perf < 0.5 else 3
            state["streak"] = 0  # Reset streak pour repartir √† z√©ro

        # Feedback with enhanced support for struggling users
        if should_break:
            feedback = "Pause recommand√©e - charge cognitive √©lev√©e"
        elif in_recovery_mode:
            # Struggling user gets encouraging, actionable feedback
            recovery_messages = [
                "C'est normal de faire des erreurs, c'est comme √ßa qu'on apprend!",
                "On va y aller doucement - des questions plus simples arrivent",
                "Prends ton temps, chaque question est une opportunit√©",
                "Tu progresses m√™me quand tu te trompes - continue!",
            ]
            import random as _r
            feedback = _r.choice(recovery_messages)
            should_reduce = True  # Force difficulty reduction
        elif not is_correct and state["streak"] <= -3:
            feedback = "Essaie un niveau plus facile"
        elif is_correct and state["streak"] >= 5:
            feedback = "Excellent! Pr√™t pour plus de challenge?"
        elif is_correct and consecutive_errors > 0:
            # Just recovered from errors
            feedback = "Super! Tu as trouv√©!"
        elif is_correct:
            feedback = "Bien jou√©!"
        else:
            feedback = "Pas grave, la prochaine sera la bonne"

        # 8. Accumuler XP total
        state["total_xp"] = state.get("total_xp", 0) + xp_earned

        # 9. Auto-save en DB (toutes les 5 r√©ponses pour √©viter trop d'I/O)
        if len(state["responses"]) % 5 == 0:
            self.save_state(user_id)

        return AnswerResult(
            mastery_change=mastery_change,
            xp_earned=xp_earned,
            next_review_days=interval,
            accuracy_recent=accuracy,
            should_reduce_difficulty=should_reduce,
            should_take_break=should_break,
            feedback=feedback
        )

    def get_user_stats(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re les statistiques d'un utilisateur"""
        state = self._get_user_state(user_id)

        # FSRS stats
        fsrs_stats = {}
        for topic_id, card in state["fsrs_cards"].items():
            fsrs_stats[topic_id] = {
                "stability": card.stability,
                "reps": card.reps,
                "retrievability": self._get_retrievability(state, topic_id)
            }

        # Recent performance
        recent = state["responses"][-20:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / max(1, len(recent))

        cognitive_load, _ = self._assess_cognitive_load(state)

        return {
            "mastery": state["mastery"],
            "fsrs": fsrs_stats,
            "streak": state["streak"],
            "recent_accuracy": accuracy,
            "cognitive_load": cognitive_load,
            "total_responses": len(state["responses"]),
            "total_xp": state.get("total_xp", 0)
        }

    def reset_session(self, user_id: str, save: bool = True):
        """Reset pour une nouvelle session (sauvegarde avant reset)"""
        if save:
            self.save_state(user_id)

        state = self._get_user_state(user_id)
        state["cognitive_detector"] = CognitiveLoadDetector()
        state["streak"] = 0
        state["responses"] = []  # Reset r√©ponses de session

        # AI Tutor v2.0: Incr√©menter le compteur de sessions
        self._increment_session_count(state)

        logger.info(f"Session reset for {user_id}")

    def get_engine_info(self) -> Dict[str, Any]:
        """Informations sur le moteur"""
        return {
            "version": "4.3 LEAN + AI Tutor v2.0",
            "modules": 5,
            "features": [
                "DB Persistence",
                "Auto-save",
                "Auto-load",
                "Quick Wins (recovery mode)",
                "Early Game Protection",
                "User Performance Level",
                "AI Tutor v2.0 - M√©moire cross-session",
                "AI Tutor v2.0 - D√©tection patterns d'erreurs",
                "AI Tutor v2.0 - Motivation adaptative",
                "AI Tutor v2.0 - Pr√©diction de difficult√©",
                "AI Tutor v2.0 - Micro-le√ßons cibl√©es",
            ],
            "modules_list": [
                {"name": "FSRS", "research": "Pimsleur (moderne)", "benefit": "Timing optimal des r√©visions"},
                {"name": "Testing Effect", "research": "Dunlosky (2013)", "benefit": "Quiz actif > relecture"},
                {"name": "Adaptive Difficulty", "research": "Vygotsky, Bjork", "benefit": "Zone optimale"},
                {"name": "Cognitive Load", "research": "Sweller (1988)", "benefit": "D√©tection fatigue"},
                {"name": "Interleaving", "research": "Rohrer (2007)", "benefit": "+43% discrimination"},
                {"name": "AI Tutor v2.0", "research": "Simulation NewMars 2024", "benefit": "100% succ√®s tous profils"},
            ],
            "removed_modules": [
                "Forgetting Curve (doublon FSRS)",
                "Emotional Encoding (artificiel)",
                "Dual Coding (pas de vraies images)",
                "Chunking (contenu d√©j√† d√©coup√©)",
                "Elaborative (GPT fait d√©j√†)",
                "Pre-sleep (impr√©cis)",
                "Confidence Tracking (gens mentent)",
                "Transfer Learning (peu de gain)",
                "Variation Practice (doublon)"
            ],
            "philosophy": "Less is more. 5 modules solides > 16 modules dilu√©s."
        }

    def get_all_users(self) -> List[str]:
        """R√©cup√®re la liste de tous les utilisateurs en DB"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT user_id FROM lean_user_states")
            users = [row[0] for row in cursor.fetchall()]
            conn.close()
            return users
        except Exception as e:
            logger.error(f"Erreur get_all_users: {e}")
            return []

    # =========================================================================
    # SKILL-AWARE DIFFICULTY (Connexion SkillBridge)
    # =========================================================================

    def get_skill_adjusted_difficulty(
        self,
        user_id: str,
        topic_id: str,
        mastery: int,
        task_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Calcule la difficult√© en tenant compte du skill graph.

        Combine:
        1. La difficult√© standard du learning engine
        2. La distance de comp√©tence si une t√¢che est fournie

        Args:
            user_id: ID utilisateur
            topic_id: ID du topic
            mastery: Ma√Ætrise actuelle (0-100)
            task_context: T√¢che optionnelle pour calcul de distance

        Returns:
            Dict avec difficulty ajust√©e et m√©tadonn√©es
        """
        # 1. Calcul standard
        params = self.get_next_question(user_id, topic_id, mastery)
        base_difficulty = params.difficulty

        # 2. Si pas de contexte de t√¢che, retourner le calcul standard
        if not task_context:
            return {
                "difficulty": base_difficulty,
                "difficulty_name": params.difficulty_name,
                "source": "learning_engine",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": 0
            }

        # 3. Calculer la distance de skill si possible
        try:
            from services.skill_bridge import get_skill_bridge
            bridge = get_skill_bridge()
            distance = bridge.calculate_task_distance(user_id, task_context)

            # Ajustement bas√© sur la distance
            skill_adjustment = 0
            if distance.total_distance >= 0.6:
                skill_adjustment = -2  # Trop dur, r√©duire
            elif distance.total_distance >= 0.4:
                skill_adjustment = -1  # Difficile, r√©duire l√©g√®rement
            elif distance.total_distance < 0.2:
                skill_adjustment = 1   # Trop facile, augmenter

            # Appliquer l'ajustement
            adjusted_difficulty = max(1, min(5, base_difficulty + skill_adjustment))

            return {
                "difficulty": adjusted_difficulty,
                "difficulty_name": self.DIFFICULTY_LEVELS[adjusted_difficulty]["name"],
                "source": "learning_engine + skill_bridge",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": skill_adjustment,
                "task_distance": distance.total_distance,
                "is_appropriate": distance.is_appropriate,
                "missing_prerequisites": distance.missing_prerequisites,
                "recommendation": distance.recommendation
            }

        except ImportError:
            logger.debug("SkillBridge not available, using standard difficulty")
            return {
                "difficulty": base_difficulty,
                "difficulty_name": params.difficulty_name,
                "source": "learning_engine",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": 0
            }
        except Exception as e:
            logger.warning(f"Error calculating skill distance: {e}")
            return {
                "difficulty": base_difficulty,
                "difficulty_name": params.difficulty_name,
                "source": "learning_engine (skill error)",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": 0,
                "error": str(e)
            }

    def map_effort_to_difficulty(self, effort: str) -> int:
        """
        Mappe l'effort d'une t√¢che (XS/S/M/L) √† un niveau de difficult√© (1-5).

        Utilis√© pour aligner les t√¢ches de projet avec le syst√®me de difficult√©.
        """
        mapping = {
            "XS": 1,  # Tr√®s facile
            "S": 2,   # Facile
            "M": 3,   # Moyen
            "L": 4,   # Difficile
        }
        return mapping.get(effort, 3)

    def difficulty_to_effort(self, difficulty: int) -> str:
        """
        Mappe un niveau de difficult√© (1-5) √† un effort de t√¢che (XS/S/M/L).

        Inverse de map_effort_to_difficulty.
        """
        if difficulty <= 1:
            return "XS"
        elif difficulty == 2:
            return "S"
        elif difficulty == 3:
            return "M"
        else:
            return "L"


# Instance globale
lean_engine = LeanLearningEngine()
