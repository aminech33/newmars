# üìò Backend Adaptatif - Documentation Technique

## üéØ Vue d'Ensemble

Backend Python pour syst√®me d'apprentissage adaptatif propuls√© par Gemini AI et algorithme SM-2++ optimis√© pour procrastinateurs.

## üèóÔ∏è Architecture

### Stack Technique
- **Framework** : FastAPI 0.100+
- **AI** : Google Gemini Pro
- **Validation** : Pydantic 2.0+
- **Serveur** : Uvicorn (ASGI)

### Structure des Dossiers

```
backend/
‚îú‚îÄ‚îÄ main.py                    # Point d'entr√©e FastAPI
‚îú‚îÄ‚îÄ config.py                  # Configuration centralis√©e
‚îú‚îÄ‚îÄ requirements.txt           # D√©pendances
‚îú‚îÄ‚îÄ .env                       # Variables d'environnement
‚îú‚îÄ‚îÄ env.example               # Template de config
‚îÇ
‚îú‚îÄ‚îÄ models/                   # Mod√®les de donn√©es (Pydantic)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ user.py              # User, UserProfile
‚îÇ   ‚îú‚îÄ‚îÄ course.py            # Course, Topic
‚îÇ   ‚îî‚îÄ‚îÄ learning.py          # Question, Session, Feedback
‚îÇ
‚îú‚îÄ‚îÄ services/                # Services m√©tier
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ gemini_service.py   # Int√©gration Gemini AI
‚îÇ
‚îú‚îÄ‚îÄ routes/                  # Routes API
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îî‚îÄ‚îÄ learning.py         # Endpoints d'apprentissage
‚îÇ
‚îî‚îÄ‚îÄ utils/                   # Utilitaires
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îî‚îÄ‚îÄ sm2_algorithm.py    # Algorithme SM-2++
```

## üß† Algorithme SM-2++ (Spaced Repetition)

### Principe de Base

L'algorithme SM-2++ est une am√©lioration de SM-2 (SuperMemo 2) adapt√© aux procrastinateurs.

### Caract√©ristiques Principales

#### 1. **P√©nalit√© Douce pour Procrastination**

```python
skip_penalty = min(skip_days * 0.1, 1.0)
adjusted_quality = max(0, quality - skip_penalty)
```

- P√©nalit√© de **0.1 point par jour** de retard
- Max **-1 point** (pas √©crasant)
- Si 5 jours de skip ‚Üí -0.5 points seulement

#### 2. **Forgiveness System**

```python
if consecutive_skips > 0:
    forgiveness_factor = 1.0 - (consecutive_skips * 0.1)
    new_interval = int(new_interval * forgiveness_factor)
```

- R√©duit l'intervalle de r√©vision apr√®s skips
- **10% de r√©duction par skip cons√©cutif**
- Max **-50%** de l'intervalle
- Permet de ne pas √™tre submerg√© apr√®s une pause

#### 3. **Difficulty Decay Automatique**

```python
if skip_days > 0:
    decay = skip_days * 0.05  # 5% par jour
    mastery_level = max(0, mastery_level - (decay * 100))
```

- Baisse automatique de la difficult√© apr√®s inactivit√©
- **5% de baisse par jour** de skip
- Questions plus faciles au retour ‚Üí succ√®s rapide ‚Üí remotivation

#### 4. **Zone de D√©veloppement Proximal (ZDP)**

Adaptation dynamique de la difficult√© selon :
- **Niveau de ma√Ætrise** (0-100%)
- **Taux de r√©ussite** r√©cent (0-1)
- **Jours d'inactivit√©**

```python
def determine_difficulty(mastery_level, success_rate, skip_days):
    # Ajuste pour rester dans la ZDP (ni trop facile, ni trop dur)
    if mastery_level < 30:
        return "easy"
    elif mastery_level < 60:
        return "medium" if 0.5 < success_rate < 0.8 else adaptive
    else:
        return "hard" if success_rate > 0.7 else "medium"
```

### Formules Math√©matiques

#### Ease Factor
```
EF' = EF + (0.1 - (5 - q) * (0.08 + (5 - q) * 0.02))
```
- `EF` = Ease Factor actuel (1.3 - 2.5)
- `q` = Qualit√© de la r√©ponse (0-5, ajust√©e par skip_penalty)

#### Intervalle de R√©vision
```
Si q < 3:  I = 1                    (√©chec, restart)
Si n = 1:  I = 1                    (premi√®re fois)
Si n = 2:  I = 6                    (deuxi√®me fois)
Sinon:     I = I(pr√©c√©dent) * EF    (exponentiel)
```

#### Changement de Ma√Ætrise
```
Si correct:
  ŒîM = base_gain * speed_bonus * mastery_penalty
  
base_gain:
  - easy: +5 points
  - medium: +10 points
  - hard: +15 points

speed_bonus:
  - 50%+ plus rapide: +3 points
  - 20%+ plus rapide: +1 point

mastery_penalty:
  - >80%: *0.7
  - >90%: *0.5
```

## ü§ñ Int√©gration Gemini AI

### Service Gemini

Le `GeminiService` g√®re toute l'interaction avec l'API Gemini.

#### G√©n√©ration de Questions Adaptatives

```python
async def generate_question(
    topic_name: str,
    difficulty: str,
    mastery_level: int,
    learning_style: Optional[str] = None,
    weak_areas: List[str] = [],
    context: Optional[str] = None
) -> Question
```

**Prompt Engineering** :
- Adapt√© au **profil de l'apprenant** (niveau, style, faiblesses)
- Ton **encourageant** pour procrastinateurs
- Format JSON strict pour parsing automatique
- Exemples visuels si style = "visual"
- Questions pratiques si style = "practical"

#### G√©n√©ration d'Encouragements

```python
async def generate_encouragement(
    is_correct: bool,
    streak: int,
    mastery_change: int
) -> str
```

Messages personnalis√©s selon :
- R√©sultat (correct/incorrect)
- Streak actuel
- Progression de la ma√Ætrise

**Exemples** :
- ‚úÖ Correct + streak 5 : "üéâ Incroyable ! 5 jours d'affil√©e, tu es en feu !"
- ‚ùå Incorrect : "üí™ Pas grave ! On apprend de nos erreurs, r√©essaye !"

### Fallback System

Si Gemini √©choue (API down, parsing error) :
- Question g√©n√©rique cr√©√©e automatiquement
- Message d'encouragement par d√©faut
- **Service jamais bloqu√©**

## üì° API Endpoints

### 1. D√©marrer une Session

```
POST /api/learning/start-session
```

**Request** :
```json
{
  "course_id": "python-101",
  "topic_id": "functions",
  "user_id": "user123"
}
```

**Response** :
```json
{
  "session_id": "uuid-xxx",
  "message": "Session d'apprentissage d√©marr√©e !",
  "ready_for_question": true
}
```

### 2. Obtenir une Question

```
GET /api/learning/next-question/{session_id}
```

**Response** :
```json
{
  "question_id": "uuid-yyy",
  "question_text": "Quelle est la sortie de...",
  "options": [
    {"id": "opt1", "text": "Option A"},
    {"id": "opt2", "text": "Option B"}
  ],
  "difficulty": "medium",
  "mastery_level": 45,
  "estimated_time": 60,
  "hints": ["Pense aux types de donn√©es"]
}
```

### 3. Soumettre une R√©ponse

```
POST /api/learning/submit-answer/{session_id}
```

**Request** :
```json
{
  "question_id": "uuid-yyy",
  "user_answer": "Option B",
  "time_taken": 45,
  "confidence": 0.8
}
```

**Response** :
```json
{
  "is_correct": true,
  "explanation": "Ta ma√Ætrise est maintenant √† 55%",
  "encouragement": "üéâ Excellent ! Continue !",
  "next_action": "continue",
  "difficulty_adjustment": null,
  "xp_earned": 25,
  "mastery_change": +10,
  "streak_info": {
    "current_streak": 3,
    "message": "üî• 3 bonnes r√©ponses d'affil√©e !"
  }
}
```

### 4. Progression

```
GET /api/learning/progress/{session_id}
```

**Response** :
```json
{
  "session_id": "uuid-xxx",
  "questions_answered": 10,
  "correct_answers": 7,
  "accuracy": 70.0,
  "xp_earned": 250,
  "mastery_level": 55,
  "success_rate": 70.0,
  "current_streak": 3,
  "next_review_in_days": 6
}
```

## üéÆ Gamification

### Syst√®me XP

```python
base_xp = {
    "easy": 10,
    "medium": 20,
    "hard": 35
}

streak_multiplier = 1.0 + (min(streak, 30) * 0.05)
total_xp = base_xp * streak_multiplier

# Bonus premi√®re du jour
if is_first_of_day:
    total_xp += 50
```

**Exemples** :
- Question facile : **10 XP**
- Question medium + streak 5 : **20 * 1.25 = 25 XP**
- Question hard + streak 10 + premi√®re du jour : **35 * 1.5 + 50 = 102 XP**

## üîí Configuration

### Variables d'Environnement

```env
# API Keys (obligatoire)
GEMINI_API_KEY=your_key_here

# Serveur (optionnel)
HOST=0.0.0.0
PORT=8000
DEBUG=True

# Algorithme SM-2++ (optionnel)
MIN_EASE_FACTOR=1.3
MAX_EASE_FACTOR=2.5
SKIP_PENALTY=0.1
DIFFICULTY_DECAY_RATE=0.05
```

## üìä M√©triques et Suivi

### Par Topic

- `mastery_level` : 0-100 (niveau de ma√Ætrise)
- `ease_factor` : 1.3-2.5 (facilit√© m√©moris√©e)
- `interval` : jours jusqu'√† prochaine r√©vision
- `repetitions` : nombre de r√©visions r√©ussies
- `success_rate` : taux de r√©ussite (0-1)
- `consecutive_skips` : skips cons√©cutifs

### Par Session

- Questions r√©pondues
- Bonnes r√©ponses
- Pr√©cision
- XP gagn√©
- Streak actuel

## üöÄ Prochaines √âtapes

### TODO #7 : Machine Learning

Ajouter d√©tection automatique du style d'apprentissage :
- Analyser les patterns de r√©ponse
- Clustering d'apprenants similaires
- Pr√©diction du meilleur moment pour apprendre

### TODO #8 : Connexion Frontend

Int√©grer avec React/TypeScript :
- Appels API depuis `src/utils/`
- State management avec Zustand
- UI components pour questions/feedback

## üìö Ressources

- [SuperMemo Algorithm](https://www.supermemo.com/en/blog/application-of-a-computer-to-improve-the-results-obtained-in-working-with-the-supermemo-method)
- [Zone de D√©veloppement Proximal (Vygotsky)](https://fr.wikipedia.org/wiki/Zone_proximale_de_d%C3%A9veloppement)
- [Gemini API Docs](https://ai.google.dev/docs)
- [FastAPI Docs](https://fastapi.tiangolo.com/)

## üéì Concepts Psycho-P√©dagogiques

### Pourquoi ces choix ?

1. **P√©nalit√© douce** : √âviter la culpabilisation des procrastinateurs
2. **Forgiveness** : Permettre les pauses sans punition excessive
3. **Difficulty decay** : Succ√®s rapide au retour ‚Üí remotivation
4. **ZDP** : Toujours "juste assez difficile" pour maintenir l'engagement
5. **Feedback positif** : Ton encourageant, jamais critique

### Recherches Appliqu√©es

- **Spaced Repetition** : +200% r√©tention long terme
- **Adaptive Learning** : +40% vitesse d'apprentissage
- **Gamification** : +60% engagement
- **Forgiveness Systems** : -70% abandons

---

**Version** : 1.0.0  
**Derni√®re mise √† jour** : 2025-12-08
