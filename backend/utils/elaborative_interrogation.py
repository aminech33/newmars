"""
‚ùì ELABORATIVE INTERROGATION ENGINE
Bas√© sur la technique d'Interrogation √âlaborative (Pressley et al., 1987)

Principe scientifique:
- Poser des questions "Pourquoi?" et "Comment?" sur les faits am√©liore la r√©tention
- Force l'apprenant √† g√©n√©rer des connexions avec ses connaissances existantes
- Active la m√©moire s√©mantique et cr√©e des "hooks" pour le rappel

Recherche:
- Pressley et al. (1987): First demonstration of elaborative interrogation
- Woloshyn et al. (1994): Extension to various domains
- Dunlosky et al. (2013): Meta-analysis showing high utility
- McDaniel & Donnelly (1996): Generation effect combined

Efficacit√©:
- +20-50% de r√©tention vs lecture simple
- Particuli√®rement efficace pour les faits et concepts

Impl√©mentation:
- G√©n√®re automatiquement des questions d'interrogation
- Adapte le type de question au contenu
- Track les r√©ponses g√©n√©r√©es pour renforcement
"""

import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from enum import Enum
import re
import random

logger = logging.getLogger(__name__)


class QuestionType(Enum):
    """Types de questions d'interrogation √©laborative"""
    WHY = "why"                    # Pourquoi ce fait est-il vrai?
    HOW = "how"                    # Comment cela fonctionne-t-il?
    CAUSE_EFFECT = "cause_effect"  # Quelle est la cause/l'effet?
    COMPARISON = "comparison"      # En quoi c'est diff√©rent de X?
    APPLICATION = "application"    # Comment appliquer cela?
    CONSEQUENCE = "consequence"    # Que se passerait-il si...?
    MECHANISM = "mechanism"        # Quel est le m√©canisme?
    PURPOSE = "purpose"            # Quel est le but/fonction?
    EVIDENCE = "evidence"          # Quelles preuves supportent cela?
    CONNECTION = "connection"      # Comment cela se relie √† X?


class ContentCategory(Enum):
    """Cat√©gories de contenu pour adapter les questions"""
    FACTUAL = "factual"           # Faits, dates, noms
    CONCEPTUAL = "conceptual"     # Concepts, th√©ories
    PROCEDURAL = "procedural"     # Processus, m√©thodes
    CAUSAL = "causal"            # Relations cause-effet
    COMPARATIVE = "comparative"   # Comparaisons
    DEFINITIONAL = "definitional"  # D√©finitions


# Templates de questions par type
QUESTION_TEMPLATES: Dict[QuestionType, List[str]] = {
    QuestionType.WHY: [
        "Pourquoi {subject} {predicate}?",
        "Quelle est la raison pour laquelle {subject} {predicate}?",
        "Comment expliquer que {subject} {predicate}?",
        "Qu'est-ce qui fait que {subject} {predicate}?",
    ],
    QuestionType.HOW: [
        "Comment {subject} {predicate}?",
        "De quelle mani√®re {subject} {predicate}?",
        "Par quel processus {subject} {predicate}?",
        "Quel m√©canisme permet √† {subject} de {predicate}?",
    ],
    QuestionType.CAUSE_EFFECT: [
        "Quelle est la cause de {effect}?",
        "Quel effet {cause} a-t-il?",
        "Que provoque {cause}?",
        "Qu'est-ce qui entra√Æne {effect}?",
    ],
    QuestionType.COMPARISON: [
        "En quoi {subject1} diff√®re de {subject2}?",
        "Quels sont les points communs entre {subject1} et {subject2}?",
        "Pourquoi {subject1} plut√¥t que {subject2}?",
    ],
    QuestionType.APPLICATION: [
        "Comment appliquer {concept} dans {context}?",
        "Dans quelle situation utiliserait-on {concept}?",
        "Quel exemple illustre {concept}?",
    ],
    QuestionType.CONSEQUENCE: [
        "Que se passerait-il si {condition}?",
        "Quelles seraient les cons√©quences de {action}?",
        "Si {hypothesis}, alors quoi?",
    ],
    QuestionType.MECHANISM: [
        "Quel est le m√©canisme derri√®re {phenomenon}?",
        "Comment fonctionne {system}?",
        "Quelles sont les √©tapes de {process}?",
    ],
    QuestionType.PURPOSE: [
        "Quel est le but de {element}?",
        "√Ä quoi sert {element}?",
        "Quelle est la fonction de {element}?",
    ],
    QuestionType.EVIDENCE: [
        "Quelles preuves soutiennent {claim}?",
        "Comment v√©rifier que {fact}?",
        "Qu'est-ce qui d√©montre {assertion}?",
    ],
    QuestionType.CONNECTION: [
        "Comment {concept1} se relie √† {concept2}?",
        "Quel est le lien entre {concept1} et {concept2}?",
        "En quoi {concept1} influence {concept2}?",
    ],
}


# Mots-cl√©s pour d√©tecter la cat√©gorie de contenu
CATEGORY_KEYWORDS: Dict[ContentCategory, List[str]] = {
    ContentCategory.FACTUAL: ["est", "sont", "date", "nom", "lieu", "nombre", "mesure"],
    ContentCategory.CONCEPTUAL: ["concept", "th√©orie", "principe", "id√©e", "notion", "abstrait"],
    ContentCategory.PROCEDURAL: ["√©tape", "processus", "m√©thode", "comment faire", "proc√©dure"],
    ContentCategory.CAUSAL: ["cause", "effet", "r√©sulte", "provoque", "entra√Æne", "car"],
    ContentCategory.COMPARATIVE: ["diff√©rent", "similaire", "compar√©", "versus", "contrairement"],
    ContentCategory.DEFINITIONAL: ["d√©finition", "signifie", "d√©signe", "appel√©"],
}


# Questions recommand√©es par cat√©gorie
RECOMMENDED_QUESTIONS: Dict[ContentCategory, List[QuestionType]] = {
    ContentCategory.FACTUAL: [QuestionType.WHY, QuestionType.CONNECTION, QuestionType.PURPOSE],
    ContentCategory.CONCEPTUAL: [QuestionType.HOW, QuestionType.APPLICATION, QuestionType.COMPARISON],
    ContentCategory.PROCEDURAL: [QuestionType.MECHANISM, QuestionType.PURPOSE, QuestionType.CONSEQUENCE],
    ContentCategory.CAUSAL: [QuestionType.CAUSE_EFFECT, QuestionType.EVIDENCE, QuestionType.MECHANISM],
    ContentCategory.COMPARATIVE: [QuestionType.COMPARISON, QuestionType.CONNECTION, QuestionType.WHY],
    ContentCategory.DEFINITIONAL: [QuestionType.PURPOSE, QuestionType.APPLICATION, QuestionType.COMPARISON],
}


@dataclass
class ElaborativeQuestion:
    """Une question d'interrogation √©laborative"""
    id: str
    question_text: str
    question_type: QuestionType
    source_content: str
    expected_elements: List[str]  # √âl√©ments cl√©s attendus dans la r√©ponse
    hint: Optional[str] = None
    difficulty: float = 0.5  # 0-1
    created_at: datetime = field(default_factory=datetime.now)


@dataclass
class ElaborativeResponse:
    """R√©ponse √† une question √©laborative"""
    question_id: str
    user_response: str
    elements_found: List[str]   # √âl√©ments cl√©s trouv√©s
    completeness: float         # 0-1, compl√©tude de la r√©ponse
    depth: float               # 0-1, profondeur de l'explication
    generation_quality: float   # 0-1, qualit√© de la g√©n√©ration
    feedback: str
    timestamp: datetime = field(default_factory=datetime.now)


@dataclass
class UserElaborativeProfile:
    """Profil d'interrogation √©laborative par utilisateur"""
    user_id: str
    questions_generated: int = 0
    responses_submitted: int = 0
    average_completeness: float = 0.0
    average_depth: float = 0.0
    preferred_question_types: List[QuestionType] = field(default_factory=list)
    weak_question_types: List[QuestionType] = field(default_factory=list)
    topics_elaborated: Dict[str, int] = field(default_factory=dict)
    history: List[Dict] = field(default_factory=list)
    created_at: datetime = field(default_factory=datetime.now)


class ElaborativeInterrogationEngine:
    """
    Moteur d'interrogation √©laborative.

    G√©n√®re automatiquement des questions "Pourquoi?" et "Comment?"
    pour renforcer la compr√©hension et la m√©morisation.
    """

    def __init__(self):
        self._user_profiles: Dict[str, UserElaborativeProfile] = {}
        self._questions_db: Dict[str, ElaborativeQuestion] = {}

        logger.info("‚ùì Elaborative Interrogation Engine initialized")

    def _get_user_profile(self, user_id: str) -> UserElaborativeProfile:
        """R√©cup√®re ou cr√©e le profil utilisateur"""
        if user_id not in self._user_profiles:
            self._user_profiles[user_id] = UserElaborativeProfile(user_id=user_id)
        return self._user_profiles[user_id]

    def _generate_question_id(self) -> str:
        """G√©n√®re un ID unique pour une question"""
        return f"eq_{datetime.now().strftime('%Y%m%d%H%M%S')}_{random.randint(1000, 9999)}"

    def detect_content_category(self, content: str) -> ContentCategory:
        """
        D√©tecte la cat√©gorie de contenu.

        Args:
            content: Le texte √† analyser

        Returns:
            ContentCategory d√©tect√©e
        """
        content_lower = content.lower()
        scores: Dict[ContentCategory, int] = {cat: 0 for cat in ContentCategory}

        for category, keywords in CATEGORY_KEYWORDS.items():
            for keyword in keywords:
                if keyword in content_lower:
                    scores[category] += 1

        best_category = max(scores, key=scores.get)

        # D√©faut √† FACTUAL si aucun match
        if scores[best_category] == 0:
            return ContentCategory.FACTUAL

        return best_category

    def extract_key_elements(self, content: str) -> Dict[str, str]:
        """
        Extrait les √©l√©ments cl√©s pour les questions.

        Args:
            content: Le texte source

        Returns:
            Dict avec subject, predicate, etc.
        """
        elements = {}

        # Extraction simple bas√©e sur la structure
        sentences = content.split('.')
        if sentences:
            first_sentence = sentences[0].strip()

            # Tenter de s√©parer sujet/pr√©dicat
            parts = first_sentence.split(' ', 3)
            if len(parts) >= 2:
                elements["subject"] = parts[0]
                elements["predicate"] = " ".join(parts[1:]) if len(parts) > 1 else ""

        # Extraire les concepts cl√©s (mots avec majuscule ou entre guillemets)
        concepts = re.findall(r'"([^"]+)"|\'([^\']+)\'|([A-Z][a-z]+(?:\s+[A-Z][a-z]+)*)', content)
        flat_concepts = [c for group in concepts for c in group if c]
        if flat_concepts:
            elements["concept1"] = flat_concepts[0]
            if len(flat_concepts) > 1:
                elements["concept2"] = flat_concepts[1]

        # Extraire cause/effet si pr√©sent
        cause_match = re.search(r'(?:car|parce que|cause)\s+([^.]+)', content, re.IGNORECASE)
        if cause_match:
            elements["cause"] = cause_match.group(1).strip()

        effect_match = re.search(r'(?:donc|ainsi|r√©sulte|provoque)\s+([^.]+)', content, re.IGNORECASE)
        if effect_match:
            elements["effect"] = effect_match.group(1).strip()

        # Fallbacks
        elements.setdefault("subject", "cela")
        elements.setdefault("predicate", "est ainsi")
        elements.setdefault("concept", content[:50])
        elements.setdefault("phenomenon", content[:30])
        elements.setdefault("element", "cet √©l√©ment")
        elements.setdefault("system", "ce syst√®me")
        elements.setdefault("process", "ce processus")
        elements.setdefault("claim", "cette affirmation")
        elements.setdefault("fact", "ce fait")
        elements.setdefault("assertion", "cette assertion")
        elements.setdefault("condition", "cela change")
        elements.setdefault("action", "cette action")
        elements.setdefault("hypothesis", "cela √©tait diff√©rent")
        elements.setdefault("context", "la pratique")
        elements.setdefault("subject1", "A")
        elements.setdefault("subject2", "B")
        elements.setdefault("concept1", "ce concept")
        elements.setdefault("concept2", "un autre concept")

        return elements

    def generate_questions(
        self,
        content: str,
        topic: str = "",
        num_questions: int = 3,
        user_id: Optional[str] = None
    ) -> List[ElaborativeQuestion]:
        """
        G√©n√®re des questions d'interrogation √©laborative.

        Args:
            content: Le contenu sur lequel poser des questions
            topic: Le sujet/topic
            num_questions: Nombre de questions √† g√©n√©rer
            user_id: ID utilisateur pour personnalisation

        Returns:
            Liste de questions √©laboratives
        """
        # 1. D√©tecter la cat√©gorie
        category = self.detect_content_category(content)

        # 2. Obtenir les types de questions recommand√©s
        recommended_types = RECOMMENDED_QUESTIONS.get(category, [QuestionType.WHY, QuestionType.HOW])

        # 3. Personnaliser si profil utilisateur
        if user_id:
            profile = self._get_user_profile(user_id)
            # √âviter les types faibles, favoriser les forts
            if profile.weak_question_types:
                # Quand m√™me inclure 1 question du type faible pour renforcer
                weak_type = profile.weak_question_types[0]
                if weak_type not in recommended_types:
                    recommended_types = recommended_types[:2] + [weak_type]

        # 4. Extraire les √©l√©ments
        elements = self.extract_key_elements(content)

        # 5. G√©n√©rer les questions
        questions = []
        used_types = set()

        for i in range(num_questions):
            # S√©lectionner un type (√©viter les doublons)
            available_types = [t for t in recommended_types if t not in used_types]
            if not available_types:
                available_types = recommended_types

            q_type = random.choice(available_types)
            used_types.add(q_type)

            # S√©lectionner un template
            templates = QUESTION_TEMPLATES.get(q_type, ["Pourquoi {subject}?"])
            template = random.choice(templates)

            # Remplir le template
            try:
                question_text = template.format(**elements)
            except KeyError:
                question_text = f"Pourquoi {elements.get('subject', 'cela')} {elements.get('predicate', 'est-il ainsi')}?"

            # Cr√©er la question
            question_id = self._generate_question_id()

            # √âl√©ments attendus (simplifi√©s)
            expected = [elements.get("subject", ""), elements.get("concept1", "")]
            expected = [e for e in expected if e and len(e) > 2]

            # Hint bas√© sur le type
            hints = {
                QuestionType.WHY: "Pensez aux causes sous-jacentes et aux raisons...",
                QuestionType.HOW: "D√©crivez le processus √©tape par √©tape...",
                QuestionType.CAUSE_EFFECT: "Identifiez la cha√Æne causale...",
                QuestionType.COMPARISON: "Listez les similitudes et diff√©rences...",
                QuestionType.APPLICATION: "Donnez un exemple concret...",
                QuestionType.CONSEQUENCE: "Imaginez les effets domino...",
                QuestionType.MECHANISM: "Expliquez le fonctionnement interne...",
                QuestionType.PURPOSE: "R√©fl√©chissez √† l'objectif vis√©...",
                QuestionType.EVIDENCE: "Citez des preuves ou exemples...",
                QuestionType.CONNECTION: "Trouvez les liens et relations...",
            }

            question = ElaborativeQuestion(
                id=question_id,
                question_text=question_text,
                question_type=q_type,
                source_content=content[:200],
                expected_elements=expected,
                hint=hints.get(q_type, "R√©fl√©chissez en profondeur..."),
                difficulty=0.3 + i * 0.2  # Difficult√© croissante
            )

            questions.append(question)
            self._questions_db[question_id] = question

        # Mettre √† jour le profil
        if user_id:
            profile = self._get_user_profile(user_id)
            profile.questions_generated += num_questions
            if topic:
                profile.topics_elaborated[topic] = profile.topics_elaborated.get(topic, 0) + num_questions

        return questions

    def evaluate_response(
        self,
        question_id: str,
        user_response: str,
        user_id: Optional[str] = None
    ) -> ElaborativeResponse:
        """
        √âvalue une r√©ponse √† une question √©laborative.

        Args:
            question_id: ID de la question
            user_response: La r√©ponse de l'utilisateur
            user_id: ID utilisateur

        Returns:
            ElaborativeResponse avec √©valuation
        """
        if question_id not in self._questions_db:
            return ElaborativeResponse(
                question_id=question_id,
                user_response=user_response,
                elements_found=[],
                completeness=0.0,
                depth=0.0,
                generation_quality=0.0,
                feedback="Question non trouv√©e"
            )

        question = self._questions_db[question_id]

        # 1. V√©rifier les √©l√©ments cl√©s trouv√©s
        response_lower = user_response.lower()
        elements_found = []
        for elem in question.expected_elements:
            if elem.lower() in response_lower:
                elements_found.append(elem)

        # 2. Calculer la compl√©tude (bas√© sur longueur et structure)
        word_count = len(user_response.split())
        min_words = 20  # Minimum pour une bonne √©laboration
        completeness = min(1.0, word_count / min_words)

        # Bonus si contient des connecteurs logiques
        connectors = ["parce que", "car", "donc", "ainsi", "cependant", "en effet", "par exemple"]
        connector_count = sum(1 for c in connectors if c in response_lower)
        completeness = min(1.0, completeness + connector_count * 0.1)

        # 3. Calculer la profondeur (bas√© sur la structure)
        depth = 0.3  # Base

        # Phrases multiples = plus de profondeur
        sentence_count = user_response.count('.') + user_response.count('!')
        depth += min(0.3, sentence_count * 0.1)

        # Exemples = profondeur
        if any(ex in response_lower for ex in ["par exemple", "comme", "tel que", "notamment"]):
            depth += 0.2

        # Nuances = profondeur
        if any(nu in response_lower for nu in ["cependant", "mais", "toutefois", "n√©anmoins"]):
            depth += 0.2

        depth = min(1.0, depth)

        # 4. Qualit√© de g√©n√©ration (l'utilisateur a-t-il vraiment r√©fl√©chi?)
        generation_quality = 0.5

        # R√©ponse personnalis√©e (pas juste copi√© le contenu)
        source_words = set(question.source_content.lower().split())
        response_words = set(response_lower.split())
        overlap = len(source_words & response_words) / max(1, len(response_words))

        if overlap < 0.5:  # Moins de 50% de mots copi√©s = bon
            generation_quality += 0.3
        else:
            generation_quality -= 0.2

        # Points bonus pour les questions de suivi implicites
        if "?" in user_response:
            generation_quality += 0.2

        generation_quality = max(0.0, min(1.0, generation_quality))

        # 5. Feedback
        feedback = self._generate_feedback(completeness, depth, generation_quality, question.question_type)

        response = ElaborativeResponse(
            question_id=question_id,
            user_response=user_response,
            elements_found=elements_found,
            completeness=completeness,
            depth=depth,
            generation_quality=generation_quality,
            feedback=feedback
        )

        # Mettre √† jour le profil
        if user_id:
            profile = self._get_user_profile(user_id)
            profile.responses_submitted += 1

            # Moyenne mobile
            n = profile.responses_submitted
            profile.average_completeness += (completeness - profile.average_completeness) / n
            profile.average_depth += (depth - profile.average_depth) / n

            # Identifier les forces/faiblesses
            avg_score = (completeness + depth + generation_quality) / 3
            if avg_score >= 0.7:
                if question.question_type not in profile.preferred_question_types:
                    profile.preferred_question_types.append(question.question_type)
            elif avg_score < 0.4:
                if question.question_type not in profile.weak_question_types:
                    profile.weak_question_types.append(question.question_type)

            profile.history.append({
                "question_id": question_id,
                "question_type": question.question_type.value,
                "completeness": completeness,
                "depth": depth,
                "generation_quality": generation_quality,
                "timestamp": datetime.now().isoformat()
            })

        return response

    def _generate_feedback(
        self,
        completeness: float,
        depth: float,
        generation_quality: float,
        question_type: QuestionType
    ) -> str:
        """G√©n√®re un feedback constructif"""
        avg = (completeness + depth + generation_quality) / 3

        feedbacks = []

        if avg >= 0.8:
            feedbacks.append("üåü Excellente √©laboration!")
        elif avg >= 0.6:
            feedbacks.append("üëç Bonne r√©flexion.")
        elif avg >= 0.4:
            feedbacks.append("üìù R√©ponse acceptable mais peut √™tre am√©lior√©e.")
        else:
            feedbacks.append("üí≠ Essayez d'approfondir votre r√©flexion.")

        # Conseils sp√©cifiques
        if completeness < 0.5:
            feedbacks.append("D√©veloppez davantage votre r√©ponse.")

        if depth < 0.5:
            feedbacks.append("Ajoutez des exemples ou des nuances.")

        if generation_quality < 0.5:
            feedbacks.append("Essayez d'utiliser vos propres mots et de faire des liens personnels.")

        # Conseil sp√©cifique au type de question
        type_tips = {
            QuestionType.WHY: "Pour les questions 'Pourquoi', identifiez les causes profondes.",
            QuestionType.HOW: "Pour les questions 'Comment', d√©crivez les √©tapes ou m√©canismes.",
            QuestionType.CAUSE_EFFECT: "Pensez √† la cha√Æne compl√®te: cause ‚Üí effet ‚Üí cons√©quences.",
            QuestionType.COMPARISON: "Utilisez un tableau mental: similitudes vs diff√©rences.",
            QuestionType.APPLICATION: "Un bon exemple vaut mille explications!",
        }

        if avg < 0.6 and question_type in type_tips:
            feedbacks.append(type_tips[question_type])

        return " ".join(feedbacks)

    def get_retention_bonus(
        self,
        question_id: str,
        response_quality: float
    ) -> float:
        """
        Calcule le bonus de r√©tention bas√© sur l'interrogation √©laborative.

        Recherche: +20-50% de r√©tention avec √©laboration de qualit√©

        Args:
            question_id: ID de la question
            response_quality: Qualit√© de la r√©ponse (0-1)

        Returns:
            Multiplicateur de r√©tention (1.0 = pas de bonus)
        """
        # Base: +20% pour avoir tent√© l'√©laboration
        base_bonus = 1.2

        # Bonus qualit√©: jusqu'√† +30% suppl√©mentaire
        quality_bonus = response_quality * 0.3

        return base_bonus + quality_bonus

    def get_user_profile(self, user_id: str) -> Dict[str, Any]:
        """Retourne le profil d'interrogation √©laborative"""
        profile = self._get_user_profile(user_id)

        return {
            "user_id": profile.user_id,
            "questions_generated": profile.questions_generated,
            "responses_submitted": profile.responses_submitted,
            "average_completeness": profile.average_completeness,
            "average_depth": profile.average_depth,
            "overall_quality": (profile.average_completeness + profile.average_depth) / 2,
            "preferred_types": [t.value for t in profile.preferred_question_types],
            "weak_types": [t.value for t in profile.weak_question_types],
            "topics_elaborated": profile.topics_elaborated,
            "recommendation": self._get_recommendation(profile)
        }

    def _get_recommendation(self, profile: UserElaborativeProfile) -> str:
        """G√©n√®re une recommandation personnalis√©e"""
        if profile.responses_submitted < 5:
            return "Continuez √† pratiquer l'interrogation √©laborative pour am√©liorer votre m√©morisation."

        avg_quality = (profile.average_completeness + profile.average_depth) / 2

        if avg_quality >= 0.7:
            return "üåü Excellent travail d'√©laboration! Vos explications sont profondes et compl√®tes."
        elif avg_quality >= 0.5:
            if profile.weak_question_types:
                weak = profile.weak_question_types[0].value
                return f"üìà Bonne progression. Travaillez particuli√®rement les questions de type '{weak}'."
            return "üìà Bonne progression. Continuez √† approfondir vos explications."
        else:
            return "üí° Conseil: Prenez plus de temps pour r√©fl√©chir avant de r√©pondre. Posez-vous des sous-questions."


# Instance globale
elaborative_engine = ElaborativeInterrogationEngine()
