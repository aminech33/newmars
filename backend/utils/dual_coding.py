"""
üé® DUAL CODING ENGINE
Bas√© sur la th√©orie du Double Codage de Paivio (1971, 1986)

Principe scientifique:
- Le cerveau traite l'information via 2 canaux distincts: verbal et visuel
- L'information encod√©e dans LES DEUX canaux est 2x plus m√©morable
- Les connexions r√©f√©rentielles entre canaux renforcent la m√©moire

Recherche:
- Paivio (1971): "Imagery and Verbal Processes"
- Mayer (2001): Principes du multimedia learning
- Clark & Paivio (1991): Dual coding theory and education

Impl√©mentation:
- G√©n√®re des indices visuels pour accompagner le contenu verbal
- Recommande des types de visualisation selon le contenu
- Track l'utilisation des deux canaux pour optimiser
"""

import logging
from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, Any, Optional, List, Tuple
from enum import Enum
import re

logger = logging.getLogger(__name__)


class ContentType(Enum):
    """Types de contenu avec recommandations d'encodage"""
    CONCEPT = "concept"          # Id√©e abstraite ‚Üí sch√©ma conceptuel
    PROCESS = "process"          # √âtapes s√©quentielles ‚Üí flowchart
    COMPARISON = "comparison"    # Diff√©rences ‚Üí tableau/Venn
    HIERARCHY = "hierarchy"      # Relations ‚Üí arbre/mind map
    SPATIAL = "spatial"          # Positions ‚Üí carte/diagramme
    TEMPORAL = "temporal"        # Chronologie ‚Üí timeline
    QUANTITATIVE = "quantitative"  # Nombres ‚Üí graphique
    CAUSAL = "causal"           # Cause-effet ‚Üí diagramme fl√®ches
    PROCEDURAL = "procedural"   # Comment faire ‚Üí √©tapes illustr√©es
    FACTUAL = "factual"         # Fait simple ‚Üí image mn√©motechnique


class VisualType(Enum):
    """Types de visualisation disponibles"""
    DIAGRAM = "diagram"          # Diagramme g√©n√©ral
    FLOWCHART = "flowchart"      # Flux de processus
    MINDMAP = "mindmap"          # Carte mentale
    TIMELINE = "timeline"        # Ligne temporelle
    VENN = "venn"               # Diagramme de Venn
    TABLE = "table"             # Tableau comparatif
    GRAPH = "graph"             # Graphique (bar, line, pie)
    ICON = "icon"               # Ic√¥ne/emoji simple
    ILLUSTRATION = "illustration"  # Image descriptive
    MNEMONIC_IMAGE = "mnemonic"  # Image mn√©motechnique
    SCHEMA = "schema"           # Sch√©ma technique
    TREE = "tree"               # Structure arborescente


# Mapping content type ‚Üí visual type recommand√©
CONTENT_TO_VISUAL: Dict[ContentType, List[VisualType]] = {
    ContentType.CONCEPT: [VisualType.MINDMAP, VisualType.SCHEMA, VisualType.ICON],
    ContentType.PROCESS: [VisualType.FLOWCHART, VisualType.TIMELINE, VisualType.DIAGRAM],
    ContentType.COMPARISON: [VisualType.TABLE, VisualType.VENN, VisualType.GRAPH],
    ContentType.HIERARCHY: [VisualType.TREE, VisualType.MINDMAP, VisualType.DIAGRAM],
    ContentType.SPATIAL: [VisualType.DIAGRAM, VisualType.ILLUSTRATION, VisualType.SCHEMA],
    ContentType.TEMPORAL: [VisualType.TIMELINE, VisualType.FLOWCHART, VisualType.GRAPH],
    ContentType.QUANTITATIVE: [VisualType.GRAPH, VisualType.TABLE, VisualType.DIAGRAM],
    ContentType.CAUSAL: [VisualType.FLOWCHART, VisualType.DIAGRAM, VisualType.MINDMAP],
    ContentType.PROCEDURAL: [VisualType.FLOWCHART, VisualType.ILLUSTRATION, VisualType.TIMELINE],
    ContentType.FACTUAL: [VisualType.MNEMONIC_IMAGE, VisualType.ICON, VisualType.ILLUSTRATION],
}


# Mots-cl√©s pour d√©tecter le type de contenu
CONTENT_KEYWORDS: Dict[ContentType, List[str]] = {
    ContentType.PROCESS: ["√©tape", "processus", "comment", "proc√©dure", "m√©thode", "cycle", "phase", "s√©quence"],
    ContentType.COMPARISON: ["diff√©rence", "similaire", "compare", "versus", "vs", "contrairement", "alors que"],
    ContentType.HIERARCHY: ["cat√©gorie", "type", "sous-", "parent", "enfant", "niveau", "classe", "groupe"],
    ContentType.TEMPORAL: ["avant", "apr√®s", "date", "ann√©e", "si√®cle", "√©poque", "histoire", "chronologie"],
    ContentType.QUANTITATIVE: ["nombre", "pourcentage", "statistique", "chiffre", "mesure", "quantit√©", "taux"],
    ContentType.CAUSAL: ["cause", "effet", "r√©sultat", "cons√©quence", "provoque", "entra√Æne", "car", "parce que"],
    ContentType.PROCEDURAL: ["faire", "cr√©er", "construire", "fabriquer", "assembler", "pr√©parer", "r√©aliser"],
    ContentType.SPATIAL: ["position", "lieu", "espace", "carte", "g√©ographie", "situ√©", "localisation"],
}


@dataclass
class DualCodedContent:
    """Contenu encod√© avec les deux canaux"""
    verbal_content: str              # Le texte/explication verbal
    content_type: ContentType        # Type de contenu d√©tect√©
    recommended_visual: VisualType   # Type de visuel recommand√©
    visual_description: str          # Description du visuel √† cr√©er
    emoji_cue: str                   # Emoji comme indice visuel rapide
    mnemonic_phrase: Optional[str]   # Phrase mn√©motechnique (si applicable)
    key_elements: List[str]          # √âl√©ments cl√©s √† visualiser
    encoding_strength: float         # Force d'encodage estim√©e (0-1)
    referential_connections: List[str]  # Connexions entre canaux


@dataclass
class UserDualCodingProfile:
    """Profil d'utilisation dual coding par utilisateur"""
    user_id: str
    visual_preference: float = 0.5    # 0 = verbal only, 1 = highly visual
    best_visual_types: List[VisualType] = field(default_factory=list)
    retention_with_visual: float = 0.0   # Taux de r√©tention avec visuel
    retention_without_visual: float = 0.0  # Taux sans visuel
    total_with_visual: int = 0
    total_without_visual: int = 0
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)


class DualCodingEngine:
    """
    Moteur de double codage.

    G√©n√®re automatiquement des indices visuels pour tout contenu verbal
    et track l'efficacit√© des deux canaux par utilisateur.
    """

    def __init__(self):
        self._user_profiles: Dict[str, UserDualCodingProfile] = {}

        # Mapping emoji par domaine/concept
        self._domain_emojis: Dict[str, str] = {
            # Sciences
            "math": "üî¢", "physique": "‚öõÔ∏è", "chimie": "üß™", "biologie": "üß¨",
            "informatique": "üíª", "m√©decine": "üè•", "astronomie": "üåü",
            # Langues
            "fran√ßais": "üá´üá∑", "anglais": "üá¨üáß", "espagnol": "üá™üá∏",
            "grammaire": "üìù", "vocabulaire": "üìö", "conjugaison": "üîÑ",
            # Histoire/G√©o
            "histoire": "üìú", "g√©ographie": "üó∫Ô∏è", "√©conomie": "üìä",
            # Arts
            "musique": "üéµ", "art": "üé®", "litt√©rature": "üìñ",
            # Autres
            "sport": "‚öΩ", "cuisine": "üë®‚Äçüç≥", "droit": "‚öñÔ∏è",
        }

        # Emojis pour concepts abstraits
        self._concept_emojis: Dict[str, str] = {
            "important": "‚≠ê", "attention": "‚ö†Ô∏è", "astuce": "üí°",
            "exemple": "üìã", "d√©finition": "üìå", "formule": "üî£",
            "r√®gle": "üìè", "exception": "‚ùó", "r√©sum√©": "üìã",
            "question": "‚ùì", "r√©ponse": "‚úÖ", "erreur": "‚ùå",
        }

        logger.info("üé® Dual Coding Engine initialized")

    def _get_user_profile(self, user_id: str) -> UserDualCodingProfile:
        """R√©cup√®re ou cr√©e le profil utilisateur"""
        if user_id not in self._user_profiles:
            self._user_profiles[user_id] = UserDualCodingProfile(user_id=user_id)
        return self._user_profiles[user_id]

    def detect_content_type(self, text: str) -> ContentType:
        """
        D√©tecte automatiquement le type de contenu bas√© sur les mots-cl√©s.

        Args:
            text: Le contenu textuel √† analyser

        Returns:
            ContentType d√©tect√©
        """
        text_lower = text.lower()
        scores: Dict[ContentType, int] = {ct: 0 for ct in ContentType}

        for content_type, keywords in CONTENT_KEYWORDS.items():
            for keyword in keywords:
                if keyword in text_lower:
                    scores[content_type] += 1

        # Trouver le type avec le plus de matches
        best_type = max(scores, key=scores.get)

        # Si aucun match, d√©faut √† CONCEPT
        if scores[best_type] == 0:
            return ContentType.CONCEPT

        return best_type

    def get_visual_recommendation(
        self,
        content_type: ContentType,
        user_id: Optional[str] = None
    ) -> VisualType:
        """
        Recommande le meilleur type de visuel.

        Args:
            content_type: Type de contenu
            user_id: ID utilisateur pour personnalisation

        Returns:
            VisualType recommand√©
        """
        recommendations = CONTENT_TO_VISUAL.get(content_type, [VisualType.DIAGRAM])

        # Si on a un profil utilisateur, adapter
        if user_id:
            profile = self._get_user_profile(user_id)
            if profile.best_visual_types:
                # Chercher intersection avec les types efficaces pour cet utilisateur
                for visual in profile.best_visual_types:
                    if visual in recommendations:
                        return visual

        return recommendations[0]

    def get_emoji_cue(self, text: str, domain: Optional[str] = None) -> str:
        """
        G√©n√®re un indice emoji pour le contenu.

        Args:
            text: Le contenu
            domain: Domaine optionnel (math, histoire, etc.)

        Returns:
            Emoji appropri√©
        """
        # Priorit√© au domaine si fourni
        if domain:
            domain_lower = domain.lower()
            for key, emoji in self._domain_emojis.items():
                if key in domain_lower:
                    return emoji

        # Sinon, chercher dans le texte
        text_lower = text.lower()

        # V√©rifier concepts abstraits
        for concept, emoji in self._concept_emojis.items():
            if concept in text_lower:
                return emoji

        # V√©rifier domaines
        for key, emoji in self._domain_emojis.items():
            if key in text_lower:
                return emoji

        # D√©faut: ampoule (id√©e)
        return "üí°"

    def extract_key_elements(self, text: str, max_elements: int = 5) -> List[str]:
        """
        Extrait les √©l√©ments cl√©s √† visualiser.

        Args:
            text: Le contenu
            max_elements: Nombre max d'√©l√©ments

        Returns:
            Liste des √©l√©ments cl√©s
        """
        # Patterns pour √©l√©ments importants
        patterns = [
            r'\*\*(.+?)\*\*',           # **texte en gras**
            r'__(.+?)__',               # __texte soulign√©__
            r'"(.+?)"',                 # "texte entre guillemets"
            r'\'(.+?)\'',               # 'texte entre apostrophes'
            r':\s*([A-Z][^.!?]+)',      # D√©finitions apr√®s ":"
        ]

        elements = []
        for pattern in patterns:
            matches = re.findall(pattern, text)
            elements.extend(matches)

        # D√©duplicate et limiter
        seen = set()
        unique = []
        for elem in elements:
            elem_clean = elem.strip()
            if elem_clean and elem_clean not in seen:
                seen.add(elem_clean)
                unique.append(elem_clean)

        return unique[:max_elements]

    def generate_visual_description(
        self,
        text: str,
        content_type: ContentType,
        visual_type: VisualType
    ) -> str:
        """
        G√©n√®re une description du visuel √† cr√©er.

        Args:
            text: Le contenu verbal
            content_type: Type de contenu
            visual_type: Type de visuel choisi

        Returns:
            Description textuelle du visuel
        """
        templates = {
            VisualType.FLOWCHART: "Cr√©er un flowchart montrant les √©tapes: {elements}. Utiliser des fl√®ches pour le flux.",
            VisualType.MINDMAP: "Carte mentale avec concept central: '{main}'. Branches: {elements}.",
            VisualType.TIMELINE: "Ligne temporelle avec les √©v√©nements: {elements}.",
            VisualType.VENN: "Diagramme de Venn comparant: {elements}. Zone centrale = points communs.",
            VisualType.TABLE: "Tableau comparatif avec colonnes: {elements}.",
            VisualType.GRAPH: "Graphique illustrant: {elements}. Type: bar/line selon donn√©es.",
            VisualType.TREE: "Arborescence hi√©rarchique: {elements}.",
            VisualType.SCHEMA: "Sch√©ma technique montrant: {elements}.",
            VisualType.ILLUSTRATION: "Illustration repr√©sentant: {elements}.",
            VisualType.MNEMONIC_IMAGE: "Image mn√©motechnique associant: {elements}.",
            VisualType.ICON: "Ic√¥ne simple repr√©sentant le concept cl√©.",
            VisualType.DIAGRAM: "Diagramme montrant les relations entre: {elements}.",
        }

        elements = self.extract_key_elements(text)
        if not elements:
            # Extraire les premiers mots significatifs
            words = [w for w in text.split()[:20] if len(w) > 3]
            elements = words[:5]

        template = templates.get(visual_type, "Visuel repr√©sentant: {elements}")

        return template.format(
            elements=", ".join(elements) if elements else "concept principal",
            main=elements[0] if elements else "concept"
        )

    def generate_mnemonic(self, text: str, elements: List[str]) -> Optional[str]:
        """
        G√©n√®re une phrase mn√©motechnique si applicable.

        Args:
            text: Le contenu
            elements: √âl√©ments cl√©s

        Returns:
            Phrase mn√©motechnique ou None
        """
        if len(elements) < 3:
            return None

        # Prendre les premi√®res lettres
        initials = [e[0].upper() for e in elements[:7] if e]

        if len(initials) >= 3:
            return f"M√©mo: {''.join(initials)} (pour retenir: {', '.join(elements[:len(initials)])})"

        return None

    def calculate_encoding_strength(
        self,
        has_visual: bool,
        has_mnemonic: bool,
        key_elements_count: int,
        content_type: ContentType
    ) -> float:
        """
        Calcule la force d'encodage estim√©e.

        Bas√© sur la recherche:
        - Dual coding double la r√©tention (Paivio)
        - Mn√©moniques +25% (Bellezza, 1981)
        - Plus d'√©l√©ments = plus de hooks

        Returns:
            Score 0-1 de force d'encodage
        """
        base_strength = 0.4  # Verbal seul

        if has_visual:
            base_strength += 0.35  # +35% avec visuel (dual coding)

        if has_mnemonic:
            base_strength += 0.15  # +15% avec mn√©monique

        # Bonus pour √©l√©ments (plus de "hooks" = meilleure r√©tention)
        element_bonus = min(0.1, key_elements_count * 0.02)
        base_strength += element_bonus

        # Certains types sont naturellement plus m√©morables
        type_bonus = {
            ContentType.SPATIAL: 0.05,    # Images spatiales tr√®s m√©morables
            ContentType.TEMPORAL: 0.03,    # Stories/chronologies
            ContentType.CAUSAL: 0.03,      # Cause-effet = logique
        }
        base_strength += type_bonus.get(content_type, 0)

        return min(1.0, base_strength)

    def encode(
        self,
        verbal_content: str,
        domain: Optional[str] = None,
        user_id: Optional[str] = None
    ) -> DualCodedContent:
        """
        Encode le contenu avec les deux canaux (verbal + visuel).

        Args:
            verbal_content: Le texte √† encoder
            domain: Domaine optionnel pour contexte
            user_id: ID utilisateur pour personnalisation

        Returns:
            DualCodedContent avec toutes les informations d'encodage
        """
        # 1. D√©tecter le type de contenu
        content_type = self.detect_content_type(verbal_content)

        # 2. Recommander le type de visuel
        visual_type = self.get_visual_recommendation(content_type, user_id)

        # 3. G√©n√©rer l'indice emoji
        emoji = self.get_emoji_cue(verbal_content, domain)

        # 4. Extraire les √©l√©ments cl√©s
        key_elements = self.extract_key_elements(verbal_content)

        # 5. G√©n√©rer la description du visuel
        visual_description = self.generate_visual_description(
            verbal_content, content_type, visual_type
        )

        # 6. G√©n√©rer mn√©monique si possible
        mnemonic = self.generate_mnemonic(verbal_content, key_elements)

        # 7. Calculer la force d'encodage
        encoding_strength = self.calculate_encoding_strength(
            has_visual=True,
            has_mnemonic=mnemonic is not None,
            key_elements_count=len(key_elements),
            content_type=content_type
        )

        # 8. Connexions r√©f√©rentielles (liens verbal ‚Üî visuel)
        connections = []
        if key_elements:
            connections = [f"{emoji} ‚Üí {elem}" for elem in key_elements[:3]]

        return DualCodedContent(
            verbal_content=verbal_content,
            content_type=content_type,
            recommended_visual=visual_type,
            visual_description=visual_description,
            emoji_cue=emoji,
            mnemonic_phrase=mnemonic,
            key_elements=key_elements,
            encoding_strength=encoding_strength,
            referential_connections=connections
        )

    def record_retention(
        self,
        user_id: str,
        was_recalled: bool,
        had_visual: bool
    ) -> None:
        """
        Enregistre le r√©sultat de r√©tention pour optimisation.

        Args:
            user_id: ID utilisateur
            was_recalled: Si le contenu a √©t√© rappel√©
            had_visual: Si un visuel √©tait pr√©sent
        """
        profile = self._get_user_profile(user_id)

        if had_visual:
            profile.total_with_visual += 1
            # Moyenne mobile
            weight = 1 / profile.total_with_visual
            if was_recalled:
                profile.retention_with_visual += weight * (1 - profile.retention_with_visual)
            else:
                profile.retention_with_visual += weight * (0 - profile.retention_with_visual)
        else:
            profile.total_without_visual += 1
            weight = 1 / profile.total_without_visual
            if was_recalled:
                profile.retention_without_visual += weight * (1 - profile.retention_without_visual)
            else:
                profile.retention_without_visual += weight * (0 - profile.retention_without_visual)

        # Mettre √† jour la pr√©f√©rence visuelle
        if profile.total_with_visual >= 5 and profile.total_without_visual >= 5:
            # Calcul du b√©n√©fice visuel
            visual_benefit = profile.retention_with_visual - profile.retention_without_visual
            # Ajuster la pr√©f√©rence (0.5 = neutre)
            profile.visual_preference = 0.5 + visual_benefit

        profile.updated_at = datetime.now()

    def get_user_profile(self, user_id: str) -> Dict[str, Any]:
        """Retourne le profil dual coding de l'utilisateur"""
        profile = self._get_user_profile(user_id)

        return {
            "user_id": profile.user_id,
            "visual_preference": profile.visual_preference,
            "preference_description": self._describe_preference(profile.visual_preference),
            "retention_with_visual": profile.retention_with_visual,
            "retention_without_visual": profile.retention_without_visual,
            "visual_benefit": profile.retention_with_visual - profile.retention_without_visual,
            "total_samples": profile.total_with_visual + profile.total_without_visual,
            "best_visual_types": [v.value for v in profile.best_visual_types],
            "recommendation": self._get_recommendation(profile)
        }

    def _describe_preference(self, pref: float) -> str:
        """D√©crit la pr√©f√©rence visuelle en texte"""
        if pref < 0.3:
            return "Apprenant verbal - pr√©f√®re les explications textuelles"
        elif pref < 0.45:
            return "L√©g√®re pr√©f√©rence verbale"
        elif pref < 0.55:
            return "√âquilibr√© - utilise les deux canaux efficacement"
        elif pref < 0.7:
            return "L√©g√®re pr√©f√©rence visuelle"
        else:
            return "Apprenant visuel - b√©n√©ficie fortement des visuels"

    def _get_recommendation(self, profile: UserDualCodingProfile) -> str:
        """G√©n√®re une recommandation personnalis√©e"""
        if profile.total_with_visual + profile.total_without_visual < 10:
            return "Continuez √† explorer les deux modes pour optimiser votre apprentissage"

        benefit = profile.retention_with_visual - profile.retention_without_visual

        if benefit > 0.15:
            return "Utilisez syst√©matiquement des visuels - votre r√©tention est significativement meilleure (+{:.0%})".format(benefit)
        elif benefit > 0.05:
            return "Les visuels vous aident mod√©r√©ment - utilisez-les pour les concepts difficiles"
        elif benefit > -0.05:
            return "Les deux modes fonctionnent bien pour vous - variez selon le contenu"
        else:
            return "Vous √™tes plus efficace avec les explications textuelles - focus sur la compr√©hension verbale"


# Instance globale
dual_coding_engine = DualCodingEngine()
