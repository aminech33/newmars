"""
Learning Engine v4.8 LEAN

5 modules scientifiques:
1. FSRS - Spaced Repetition (Pimsleur)
2. Testing Effect - Quiz actif (Dunlosky 2013)
3. Adaptive Difficulty - Zone proximale (Vygotsky)
4. State Detection - Cognitive load + fatigue + flow (Sweller, Csikszentmihalyi)
5. Interleaving - M√©lange des sujets (Rohrer 2007)

+ Persistance SQLite
+ Streak protection, milestones, feedback adaptatif
"""

import logging
import sqlite3
import json
import random
from datetime import datetime, timedelta
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
from pathlib import Path

# Imports essentiels uniquement
from utils.fsrs_algorithm import FSRS, FSRSCard, Rating
from utils.cognitive_load import CognitiveLoadDetector

logger = logging.getLogger(__name__)

# Chemin de la base de donn√©es
DB_PATH = Path(__file__).parent.parent / "data" / "learning.db"


@dataclass
class QuestionParams:
    """Param√®tres pour la prochaine question"""
    difficulty: int  # 1-5
    difficulty_name: str  # "VERY_EASY" -> "EXPERT"
    topic_id: str
    fsrs_interval: float
    retrievability: float
    cognitive_load: str
    should_take_break: bool
    interleave_suggested: bool  # Sugg√©rer de changer de sujet


@dataclass
class AnswerResult:
    """R√©sultat apr√®s traitement d'une r√©ponse"""
    mastery_change: int
    xp_earned: int
    next_review_days: float
    accuracy_recent: float
    should_reduce_difficulty: bool
    should_take_break: bool
    feedback: str
    # Nouvelles m√©triques motivation
    streak_protected: bool = False
    decay_warnings: list = None

    def __post_init__(self):
        if self.decay_warnings is None:
            self.decay_warnings = []


@dataclass
class UserState:
    """
    √âtat unifi√© de l'utilisateur (v4.8).

    Fusionne les 3 d√©tecteurs d'√©tat (Cognitive Load, Fatigue, Flow)
    en une seule repr√©sentation coh√©rente.

    Indicateurs:
    - cognitive_load: "low", "medium", "high", "overload"
    - fatigue_level: "none", "early", "moderate", "severe"
    - flow_state: "below", "in_flow", "above" (zone optimale)
    - should_pause: Recommandation pause (bool√©en)
    - recovery_mode: Mode r√©cup√©ration actif (bool√©en)
    - warning_message: Message d'alerte optionnel
    """
    cognitive_load: str = "low"       # Charge cognitive (Sweller 1988)
    fatigue_level: str = "none"       # Fatigue (Krueger 1989, Posner 1990)
    flow_state: str = "below"         # √âtat de flow (Csikszentmihalyi 1990)
    should_pause: bool = False        # Recommandation pause
    recovery_mode: bool = False       # Mode r√©cup√©ration actif
    warning_message: Optional[str] = None  # Message d'alerte


class LeanLearningEngine:
    """
    Moteur d'apprentissage LEAN v4.8

    5 modules scientifiques essentiels + 4 √©l√©ments psychologiques + d√©tection √©tat unifi√©e.

    MODULES SCIENTIFIQUES:
    1. FSRS - Spaced Repetition (Pimsleur)
    2. Testing Effect - Quiz actif (Dunlosky 2013)
    3. Adaptive Difficulty - Zone proximale (Vygotsky)
    4. State Detection Unified - D√©tection √©tat holistique     5. Interleaving - M√©lange des sujets (Rohrer 2007)

    √âL√âMENTS MOTIVATION :
    1. Streak Protection - Grace days pour maintenir habitudes (Ariely 2002)
    2. Micro-Celebrations - R√©compenses al√©atoires (Skinner, Variable Ratio)
    3. Progress Milestones - Visualisation progression (Amabile 2011)
    4. Mastery Decay Warnings - Alerts r√©vision proactive

    OPTIMISATIONS v4.8 (Simplification):
    - Fusion 3 d√©tecteurs ‚Üí 1 fonction _assess_user_state()
    - UserState unifi√© (cognitive load + fatigue + flow)
    - Hi√©rarchie d√©cision difficult√© claire
    - Feedback unifi√© (√©motionnel + celebrations)

    Base scientifique Module 4:
    - Cognitive Load: Sweller 1988
    - Fatigue: Krueger 1989, Posner & Petersen 1990, Lim & Dinges 2008
    - Flow: Csikszentmihalyi 1990
    - Recovery: Wolpe 1958 (desensitization), Bandura 1977 (self-efficacy)

    + Persistance DB SQLite
    + AI Tutor v2.0 (m√©moire cross-session, d√©tection patterns)
    """

    # Niveaux de difficult√©
    DIFFICULTY_LEVELS = {
        1: {"name": "VERY_EASY", "display": "Tr√®s Facile", "xp": 5, "target_accuracy": 0.90},
        2: {"name": "EASY", "display": "Facile", "xp": 10, "target_accuracy": 0.80},
        3: {"name": "MEDIUM", "display": "Moyen", "xp": 20, "target_accuracy": 0.70},
        4: {"name": "HARD", "display": "Difficile", "xp": 35, "target_accuracy": 0.60},
        5: {"name": "EXPERT", "display": "Expert", "xp": 50, "target_accuracy": 0.50},
    }

    def __init__(self, db_path: str = None):
        # Module 1: FSRS
        self.fsrs = FSRS()

        # √âtat par utilisateur (cache m√©moire)
        self._user_states: Dict[str, Dict[str, Any]] = {}

        # Chemin DB
        self.db_path = db_path or str(DB_PATH)
        Path(self.db_path).parent.mkdir(parents=True, exist_ok=True)

        # Initialiser la table de persistance
        self._init_db()

        logger.info("üß† Lean Learning Engine v4.8 initialized")

    # =========================================================================
    # PERSISTANCE DB
    # =========================================================================

    def _init_db(self):
        """Cr√©e la table de persistance si elle n'existe pas"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                CREATE TABLE IF NOT EXISTS lean_user_states (
                    user_id TEXT PRIMARY KEY,
                    fsrs_cards TEXT,
                    mastery TEXT,
                    streak INTEGER DEFAULT 0,
                    last_topic TEXT,
                    total_xp INTEGER DEFAULT 0,
                    responses_count INTEGER DEFAULT 0,
                    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
                )
            """)

            conn.commit()
            conn.close()
            logger.info("‚úÖ Table lean_user_states initialis√©e")
        except Exception as e:
            logger.error(f"‚ùå Erreur init DB: {e}")

    def _serialize_fsrs_cards(self, cards: Dict[str, FSRSCard]) -> str:
        """S√©rialise les cartes FSRS en JSON"""
        serialized = {}
        for topic_id, card in cards.items():
            serialized[topic_id] = {
                "stability": card.stability,
                "difficulty": card.difficulty,
                "reps": card.reps,
                "lapses": card.lapses,
                "last_review": card.last_review.isoformat() if card.last_review else None
            }
        return json.dumps(serialized)

    def _deserialize_fsrs_cards(self, data: str) -> Dict[str, FSRSCard]:
        """D√©s√©rialise les cartes FSRS depuis JSON"""
        if not data:
            return {}

        try:
            parsed = json.loads(data)
            cards = {}
            for topic_id, card_data in parsed.items():
                card = FSRSCard()
                card.stability = card_data.get("stability", 0)
                card.difficulty = card_data.get("difficulty", 0.3)
                card.reps = card_data.get("reps", 0)
                card.lapses = card_data.get("lapses", 0)
                if card_data.get("last_review"):
                    card.last_review = datetime.fromisoformat(card_data["last_review"])
                cards[topic_id] = card
            return cards
        except Exception as e:
            logger.error(f"Erreur d√©s√©rialisation FSRS: {e}")
            return {}

    def save_state(self, user_id: str) -> bool:
        """Sauvegarde l'√©tat d'un utilisateur en DB"""
        if user_id not in self._user_states:
            return False

        state = self._user_states[user_id]

        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT OR REPLACE INTO lean_user_states
                (user_id, fsrs_cards, mastery, streak, last_topic, total_xp, responses_count, updated_at)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?)
            """, (
                user_id,
                self._serialize_fsrs_cards(state.get("fsrs_cards", {})),
                json.dumps(state.get("mastery", {})),
                state.get("streak", 0),
                state.get("last_topic"),
                state.get("total_xp", 0),
                len(state.get("responses", [])),
                datetime.now().isoformat()
            ))

            conn.commit()
            conn.close()
            logger.debug(f"‚úÖ √âtat sauvegard√© pour {user_id}")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur sauvegarde √©tat {user_id}: {e}")
            return False

    def load_state(self, user_id: str) -> bool:
        """Charge l'√©tat d'un utilisateur depuis la DB"""
        try:
            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            cursor.execute("""
                SELECT * FROM lean_user_states WHERE user_id = ?
            """, (user_id,))

            row = cursor.fetchone()
            conn.close()

            if not row:
                return False

            # Restaurer l'√©tat
            self._user_states[user_id] = {
                "cognitive_detector": CognitiveLoadDetector(),
                "fsrs_cards": self._deserialize_fsrs_cards(row["fsrs_cards"]),
                "responses": [],  # Reset des r√©ponses de session
                "mastery": json.loads(row["mastery"]) if row["mastery"] else {},
                "last_topic": row["last_topic"],
                "streak": row["streak"] or 0,
                "total_xp": row["total_xp"] or 0,
            }

            logger.info(f"‚úÖ √âtat charg√© pour {user_id} (mastery: {len(self._user_states[user_id]['mastery'])} topics)")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur chargement √©tat {user_id}: {e}")
            return False

    def delete_state(self, user_id: str) -> bool:
        """Supprime l'√©tat d'un utilisateur"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("DELETE FROM lean_user_states WHERE user_id = ?", (user_id,))
            conn.commit()
            conn.close()

            if user_id in self._user_states:
                del self._user_states[user_id]

            logger.info(f"‚úÖ √âtat supprim√© pour {user_id}")
            return True

        except Exception as e:
            logger.error(f"‚ùå Erreur suppression √©tat {user_id}: {e}")
            return False

    def _get_user_state(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re ou cr√©e l'√©tat d'un utilisateur (avec auto-load depuis DB)"""
        if user_id not in self._user_states:
            # Essayer de charger depuis la DB
            if not self.load_state(user_id):
                # Cr√©er un nouvel √©tat
                self._user_states[user_id] = {
                    # Module 4: Cognitive Load
                    "cognitive_detector": CognitiveLoadDetector(),
                    # FSRS cards par topic
                    "fsrs_cards": {},
                    # Historique des r√©ponses pour interleaving et stats
                    "responses": [],
                    # Ma√Ætrise par topic
                    "mastery": {},
                    # Dernier topic (pour interleaving)
                    "last_topic": None,
                    # Streak actuel
                    "streak": 0,
                    # XP total
                    "total_xp": 0,
                    # Streak Protection
                    "streak_freeze_available": 1,  # 1 jour de gr√¢ce par semaine
                    "last_practice_date": None,  # Date de derni√®re pratique
                    "streak_protected": False,  # Si streak actuellement prot√©g√©
                    # Milestones
                    "milestones_reached": [],  # Liste des milestones atteints
                    "total_questions_answered": 0,  # Total questions r√©pondues
                    "skills_mastered": 0,  # Nombre de skills √† 80%+
                    # Celebrations
                    "last_celebration": None,  # Derni√®re c√©l√©bration
                    # Cognitive Load Recovery
                    "recovery_mode": False,  # Mode r√©cup√©ration post-fatigue
                    "recovery_questions_remaining": 0,  # Questions faciles restantes
                    "session_start_time": None,  # Heure d√©but session
                }
        return self._user_states[user_id]

    # =========================================================================
    # MODULE 1: FSRS - Spaced Repetition
    # =========================================================================

    def _get_fsrs_card(self, state: Dict, topic_id: str) -> FSRSCard:
        """R√©cup√®re ou cr√©e une carte FSRS"""
        if topic_id not in state["fsrs_cards"]:
            state["fsrs_cards"][topic_id] = FSRSCard()
        return state["fsrs_cards"][topic_id]

    def _update_fsrs(self, state: Dict, topic_id: str, is_correct: bool, response_time: float) -> tuple:
        """Met √† jour FSRS et retourne (new_card, interval)"""
        card = self._get_fsrs_card(state, topic_id)

        # Convertir en rating FSRS
        if is_correct:
            if response_time < 10:
                rating = Rating.EASY
            elif response_time < 30:
                rating = Rating.GOOD
            else:
                rating = Rating.HARD
        else:
            rating = Rating.AGAIN

        new_card, interval = self.fsrs.review(card, rating)
        state["fsrs_cards"][topic_id] = new_card

        return new_card, interval

    def _get_retrievability(self, state: Dict, topic_id: str) -> float:
        """Calcule la probabilit√© de rappel actuelle"""
        card = self._get_fsrs_card(state, topic_id)
        if card.stability <= 0:
            return 1.0

        days_since = 0
        if card.last_review:
            days_since = (datetime.now() - card.last_review).days

        return self.fsrs.retrievability(days_since, card.stability)

    # =========================================================================
    # MODULE 2: TESTING EFFECT (implicite - l'app fait des quiz)
    # =========================================================================
    # Le testing effect est inh√©rent au fait qu'on pose des questions
    # Pas de code sp√©cifique n√©cessaire

    # =========================================================================
    # MODULE 3: ADAPTIVE DIFFICULTY
    # =========================================================================

    def _calculate_optimal_difficulty(
        self,
        mastery: int,
        retrievability: float,
        cognitive_load: str,
        recent_accuracy: float,
        streak: int,
        user_performance_level: float = 0.5  # 0-1, niveau de performance historique
    ) -> int:
        """
        Calcule le niveau de difficult√© optimal (1-5).

        Objectif: Zone Proximale de D√©veloppement (Vygotsky)
        - Pas trop facile (ennui)
        - Pas trop dur (frustration)
        - Juste assez challengeant (flow)

        AM√âLIORATION v4.2: S'adapte au niveau de performance de l'utilisateur.
        Un utilisateur en difficult√© re√ßoit des questions adapt√©es √† SON niveau.
        """
        # Ma√Ætrise effective = mastery pond√©r√© par performance historique
        # Un user struggling (perf=0.4) avec mastery=50 ‚Üí effective=35
        effective_mastery = mastery * (0.7 + user_performance_level * 0.6)

        # Base: difficult√© selon ma√Ætrise EFFECTIVE
        # Plafond a niveau 4 par defaut (niveau 5 = bonus streak)
        if effective_mastery < 15:
            base_level = 1
        elif effective_mastery < 30:
            base_level = 2
        elif effective_mastery < 50:
            base_level = 3
        else:
            base_level = 4  # Plafond niveau 4, niveau 5 via streak uniquement

        level = base_level

        # Ajustement retrievability: m√©moire faible = r√©vision
        # Supprime le boost niveau 5 sur haute retrievability
        # Le niveau 5 doit etre reserve aux longs streaks, pas a la memoire
        if retrievability < 0.4:
            level = max(1, level - 1)

        # Ajustement cognitive load - PLUS AGRESSIF
        if cognitive_load == "overload":
            level = 1  # Force niveau 1, pas de n√©gociation
        elif cognitive_load == "high":
            level = max(1, level - 1)

        # CLEF: Ajustement performance r√©cente (tr√®s sensible)
        # C'est ici qu'on aide les √©l√®ves en difficult√©
        if recent_accuracy < 0.4:
            level = 1  # Struggling = niveau 1, pas de n√©gociation
        elif recent_accuracy < 0.5:
            level = max(1, level - 1)
        elif recent_accuracy > 0.85 and streak >= 5:
            level = min(5, level + 1)  # streak 5 requis (etait 3)

        # Ajustement streak - PLUS R√âACTIF aux erreurs
        if streak <= -4:
            level = 1  # Force facile apr√®s 4 erreurs cons√©cutives
        elif streak <= -2:
            level = max(1, level - 1)
        elif streak >= 6 and level < 5:  # streak 6 requis (etait 4)
            level += 1

        # Consolidation pour experts: 20% de questions niveau 3 pour renforcer la m√©moire
        if mastery >= 80 and level >= 4:
            if random.random() < 0.20:
                level = 3

        return level

    def _detect_emotional_state(self, state: Dict, is_correct: bool, consecutive_errors: int) -> str:
        """
        D√©tecte l'√©tat √©motionnel de l'utilisateur pour adapter le feedback (v4.5).

        √âtats possibles:
        - "confident": Streak positif, bonne accuracy, progression
        - "frustrated": Erreurs cons√©cutives, accuracy basse, pas de progression
        - "demotivated": Baisse de performance, pauses fr√©quentes
        - "neutral": √âtat normal
        - "celebrating": Milestone atteint (streak, mastery, etc.)

        Retourne: √âtat √©motionnel d√©tect√©
        """
        responses = state.get("responses", [])

        if len(responses) < 5:
            return "neutral"

        recent = responses[-10:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / len(recent)
        streak = state.get("streak", 0)

        # CELEBRATING: Milestones
        if streak >= 10:
            return "celebrating"  # Long streak = c√©l√©bration
        if is_correct and streak >= 5:
            return "celebrating"  # Bonne s√©rie

        # V√©rifier si mastery a franchi un cap r√©cemment
        for topic_id, mastery in state.get("mastery", {}).items():
            if mastery >= 80 and len(responses) >= 2:
                # V√©rifier si on vient de franchir 80%
                prev_responses = [r for r in responses if r.get("topic_id") == topic_id]
                if len(prev_responses) >= 2:
                    # Si on √©tait en dessous de 80 il y a peu
                    if mastery >= 80 and len([r for r in prev_responses[-5:] if r.get("is_correct", False)]) >= 4:
                        return "celebrating"

        # FRUSTRATED: Erreurs cons√©cutives, blocage
        if consecutive_errors >= 3:
            return "frustrated"
        if accuracy < 0.4 and len(recent) >= 5:
            return "frustrated"

        # DEMOTIVATED: Baisse de performance
        if len(responses) >= 20:
            older_accuracy = sum(1 for r in responses[-20:-10] if r.get("is_correct", False)) / 10
            if older_accuracy - accuracy > 0.2:  # Baisse de 20%+
                return "demotivated"

        # CONFIDENT: Bonne performance stable
        if accuracy >= 0.75 and streak >= 3:
            return "confident"

        return "neutral"

    def _generate_feedback(
        self,
        emotional_state: str,
        is_correct: bool,
        streak: int,
        mastery_change: int,
        state: Dict
    ) -> str:
        """
        G√©n√®re un feedback unifi√© adapt√© (v4.8).

        Fusionne:
        - Feedback √©motionnel (v4.5) - Adapt√© √† l'√©tat √©motionnel
        - Micro-celebrations  - Surprises al√©atoires (5% chance)

        Le ton et le contenu s'adaptent √† l'√©motion + possibilit√© de bonus surprise.

        Args:
            emotional_state: √âtat √©motionnel d√©tect√©
            is_correct: R√©ponse correcte ou non
            streak: Streak actuel
            mastery_change: Changement de ma√Ætrise
            state: √âtat utilisateur (pour celebrations)

        Returns:
            Message de feedback complet (peut inclure bonus)
        """
        import random

        # =====================================================================
        # 1. MICRO-CELEBRATION AL√âATOIRE (v4.6 - 5% chance)
        # =====================================================================
        # Inspir√© de Skinner (Variable Ratio Schedule) - r√©compenses impr√©visibles
        # cr√©ent plus d'engagement que r√©compenses fixes
        if random.random() > 0.95:
            celebrations = [
                "üéÅ Surprise! +50 XP bonus pour ta r√©gularit√©!",
                "‚ú® Bonus al√©atoire: +30 XP pour ton engagement!",
                "üéâ Tu as de la chance! +40 XP bonus!",
                "üíù Cadeau surprise: +50 XP!",
            ]
            return random.choice(celebrations)

        # =====================================================================
        # 2. FEEDBACK √âMOTIONNEL ADAPTATIF         # =====================================================================

        if emotional_state == "celebrating":
            messages = [
                f"üéâ Incroyable! S√©rie de {abs(streak)} r√©ussites!",
                "üí™ Tu es en feu! Continue comme √ßa!",
                "‚≠ê Performance exceptionnelle!",
                "üöÄ Tu ma√Ætrises vraiment ce sujet!",
            ]
            return random.choice(messages)

        elif emotional_state == "frustrated":
            messages = [
                "üíô Pas de panique, on va y arriver ensemble",
                "ü§ù C'est normal de bloquer, faisons une pause strat√©gique",
                "üí° Essayons une approche diff√©rente",
                "üå± Chaque erreur est un pas vers la r√©ussite",
            ]
            return random.choice(messages)

        elif emotional_state == "demotivated":
            messages = [
                "üí™ Tu as d√©j√† progress√©, ne l√¢che rien!",
                "üéØ Rappelle-toi pourquoi tu as commenc√©",
                "üåü Chaque jour d'effort compte, m√™me les difficiles",
                "üî• Tu es plus fort que tu ne le penses",
            ]
            return random.choice(messages)

        elif emotional_state == "confident":
            if is_correct:
                messages = [
                    "‚ú® Parfait! Pr√™t pour plus de challenge?",
                    "üëè Excellente ma√Ætrise!",
                    "üéØ Pr√©cision chirurgicale!",
                    "‚ö° Tu domines ce sujet!",
                ]
            else:
                messages = [
                    "Petite erreur, mais tu as le niveau!",
                    "Juste une faute d'inattention",
                    "Tu ma√Ætrises, c'√©tait juste difficile",
                ]
            return random.choice(messages)

        else:  # neutral
            if is_correct:
                if mastery_change >= 5:
                    return "‚úì Bien jou√©! Belle progression"
                return "‚úì Correct!"
            else:
                return "‚úó Pas cette fois, mais tu vas y arriver"


    # =========================================================================
    # STREAK PROTECTION & MILESTONES
    # =========================================================================

    def _check_streak_and_update(self, state: Dict) -> tuple:
        """
        V√©rifie et met √† jour le streak avec protection .

        Retourne: (streak_message: str, streak_protected: bool)
        """
        today = datetime.now().date()
        last_practice = state.get("last_practice_date")

        # Premi√®re session
        if last_practice is None:
            state["last_practice_date"] = today
            state["streak"] = 1
            return "üî• Streak commenc√©! (1 jour)", False

        # Convertir last_practice en date si c'est un string
        if isinstance(last_practice, str):
            last_practice = datetime.fromisoformat(last_practice).date()

        days_since_last = (today - last_practice).days

        # M√™me jour = pas de changement
        if days_since_last == 0:
            return None, False

        # Pratiqu√© hier = streak continue
        if days_since_last == 1:
            state["streak"] = max(1, state.get("streak", 0) + 1)
            state["last_practice_date"] = today
            streak_count = state["streak"]

            # Messages de milestone de streak
            if streak_count == 7:
                return f"üî• 7 jours de suite! Streak hebdomadaire d√©bloqu√©e!", False
            elif streak_count == 30:
                return f"üèÜ 30 JOURS DE SUITE! Tu es une l√©gende!", False
            elif streak_count % 10 == 0:
                return f"üî• {streak_count} jours de suite! Incroyable r√©gularit√©!", False
            else:
                return f"üî• Streak: {streak_count} jours", False

        # Manqu√© 1+ jour = check protection
        if days_since_last >= 2:
            freeze_available = state.get("streak_freeze_available", 0)
            current_streak = state.get("streak", 0)

            # Protection disponible ET streak > 5 jours (worth protecting)
            if freeze_available > 0 and current_streak >= 5:
                state["streak_freeze_available"] -= 1
                state["last_practice_date"] = today
                state["streak_protected"] = True
                return f"üíô Streak Protection activ√©e! S√©rie sauvegard√©e: {current_streak} jours (reste: {freeze_available - 1} protections)", True

            # Pas de protection = reset
            else:
                old_streak = state.get("streak", 0)
                state["streak"] = 1
                state["last_practice_date"] = today
                state["streak_protected"] = False

                if old_streak >= 7:
                    return f"‚ö†Ô∏è Streak perdue (√©tait: {old_streak} jours) - Nouvelle s√©rie commenc√©e!", False
                else:
                    return f"Nouvelle s√©rie commenc√©e!", False

        return None, False

    def _check_milestones(self, state: Dict) -> list:
        """
        V√©rifie les milestones atteints et retourne les nouveaux .

        Retourne: Liste des messages de milestone
        """
        milestones_reached = state.get("milestones_reached", [])
        total_questions = state.get("total_questions_answered", 0)
        skills_mastered = state.get("skills_mastered", 0)
        messages = []

        # Milestones questions
        question_milestones = [10, 50, 100, 250, 500, 1000]
        for milestone in question_milestones:
            if total_questions >= milestone and f"questions_{milestone}" not in milestones_reached:
                milestones_reached.append(f"questions_{milestone}")
                state["milestones_reached"] = milestones_reached
                if milestone == 100:
                    messages.append(f"üíØ 100 questions r√©pondues! Taux de r√©ussite: {self._get_overall_accuracy(state):.0%}")
                else:
                    messages.append(f"üéØ {milestone} questions r√©pondues!")

        # Milestones skills
        skill_milestones = [1, 5, 10, 15, 20]
        for milestone in skill_milestones:
            if skills_mastered >= milestone and f"skills_{milestone}" not in milestones_reached:
                milestones_reached.append(f"skills_{milestone}")
                state["milestones_reached"] = milestones_reached
                if milestone == 1:
                    messages.append(f"‚≠ê Premi√®re comp√©tence ma√Ætris√©e!")
                elif milestone == 10:
                    messages.append(f"üèÜ 10 comp√©tences ma√Ætris√©es! Tu es sur la bonne voie!")
                else:
                    messages.append(f"üåü {milestone} comp√©tences ma√Ætris√©es!")

        return messages


    def _get_overall_accuracy(self, state: Dict) -> float:
        """Calcule l'accuracy globale de l'utilisateur"""
        responses = state.get("responses", [])
        if len(responses) == 0:
            return 0.0
        correct = sum(1 for r in responses if r.get("is_correct", False))
        return correct / len(responses)

    def _detect_mastery_decay(self, state: Dict) -> list:
        """
        D√©tecte les skills qui ont d√©clin√© et n√©cessitent r√©vision .

        Retourne: Liste des warnings de decay
        """
        warnings = []
        mastery = state.get("mastery", {})
        responses = state.get("responses", [])

        for topic_id, current_mastery in mastery.items():
            # Ignorer si mastery < 50% (encore en apprentissage)
            if current_mastery < 50:
                continue

            # Trouver derni√®re pratique de ce topic
            topic_responses = [r for r in responses if r.get("topic_id") == topic_id]
            if not topic_responses:
                continue

            last_response = topic_responses[-1]
            last_date = last_response.get("timestamp")
            if not last_date or not isinstance(last_date, datetime):
                continue

            days_since = (datetime.now() - last_date).days

            # Warning si pas pratiqu√© depuis 7+ jours ET mastery √©tait √©lev√©e
            if days_since >= 7 and current_mastery >= 70:
                # Estimer le decay (1% par jour approximativement)
                estimated_decay = min(days_since, 15)
                warnings.append(f"‚ö†Ô∏è '{topic_id}': {current_mastery}% (pas pratiqu√© depuis {days_since}j)")

        return warnings[:3]  # Max 3 warnings pour ne pas surcharger

    # =========================================================================
    # MODULE 4: STATE DETECTION UNIFIED     # Fusionne Cognitive Load + Fatigue + Flow en une seule √©valuation
    # =========================================================================

    def _assess_user_state(self, state: Dict) -> UserState:
        """
        √âvaluation UNIFI√âE de l'√©tat de l'utilisateur (v4.8).

        Fusionne 3 d√©tecteurs en une seule analyse holistique:
        1. Cognitive Load (Sweller 1988) - Charge cognitive
        2. Fatigue Detection (Krueger 1989, Posner 1990, Lim 2008) - Fatigue
        3. Flow State (Csikszentmihalyi 1990) - Zone optimale

        Retourne: UserState avec tous les indicateurs
        """
        responses = state.get("responses", [])
        user_state = UserState()

        # Si pas assez de donn√©es, retour √©tat neutre
        if len(responses) < 5:
            return user_state

        # =====================================================================
        # 1. COGNITIVE LOAD DETECTION (Sweller 1988)
        # =====================================================================
        assessment = state["cognitive_detector"].assess()
        user_state.cognitive_load = assessment.overall_load
        user_state.should_pause = assessment.should_pause

        # =====================================================================
        # 2. FATIGUE DETECTION (Krueger 1989, Posner 1990, Lim 2008)
        # =====================================================================

        # 2a. Dur√©e de session (>45min = risque √©lev√© - Krueger 1989)
        session_start = state.get("session_start_time")
        if session_start:
            session_duration = (datetime.now() - session_start).total_seconds() / 60
            if session_duration > 45:
                user_state.fatigue_level = "moderate"
                user_state.warning_message = "‚è∞ Session de 45+ min - Pause recommand√©e"
                user_state.should_pause = True

        # 2b. Temps de r√©ponse en augmentation (Posner & Petersen 1990)
        if user_state.fatigue_level == "none" and len(responses) >= 10:
            recent_10 = responses[-10:]
            first_5_avg = sum(r.get("response_time", 30) for r in recent_10[:5]) / 5
            last_5_avg = sum(r.get("response_time", 30) for r in recent_10[5:]) / 5

            # Augmentation >30% = signe de fatigue
            if last_5_avg > first_5_avg * 1.3:
                user_state.fatigue_level = "early"
                user_state.warning_message = "üêå Temps de r√©ponse en hausse - Fatigue d√©tect√©e"

        # 2c. Pattern correct‚Üíerreur soudaine (Lim & Dinges 2008 - micro-sleep)
        if user_state.fatigue_level == "none" and len(responses) >= 5:
            recent_5 = responses[-5:]
            # 3+ correct puis erreur = possible micro-sleep
            if all(r.get("is_correct", False) for r in recent_5[:-1]) and not recent_5[-1].get("is_correct", True):
                user_state.fatigue_level = "early"
                user_state.warning_message = "‚ö†Ô∏è Erreur inattendue apr√®s s√©rie correcte - Attention!"

        # =====================================================================
        # 3. FLOW STATE DETECTION (Csikszentmihalyi 1990)
        # =====================================================================
        # Flow = Zone optimale entre difficult√© et capacit√©

        recent_20 = responses[-20:]
        if len(recent_20) >= 10:
            accuracy = sum(1 for r in recent_20 if r.get("is_correct", False)) / len(recent_20)
            avg_difficulty = sum(r.get("difficulty", 3) for r in recent_20) / len(recent_20)

            # Zone de flow : 60-80% accuracy + difficult√© mod√©r√©e-√©lev√©e (3-4)
            if 0.60 <= accuracy <= 0.80 and 2.5 <= avg_difficulty <= 4.5:
                user_state.flow_state = "in_flow"
            elif accuracy > 0.80:
                user_state.flow_state = "below"  # Trop facile
            else:
                user_state.flow_state = "above"  # Trop difficile

        # =====================================================================
        # 4. D√âCISION RECOVERY MODE
        # =====================================================================
        # Activer r√©cup√©ration si surcharge OU fatigue mod√©r√©e
        if user_state.cognitive_load in ["high", "overload"] or user_state.fatigue_level == "moderate":
            user_state.recovery_mode = True

        return user_state

    def _initiate_recovery_mode(self, state: Dict, reason: str = "fatigue"):
        """
        Active le mode r√©cup√©ration progressive .

        Scientifique: Desensitization progressive (Wolpe 1958) +
                      Self-efficacy reconstruction (Bandura 1977)

        Mode r√©cup√©ration = 3 √©tapes:
        1. 5 questions niveau 1 (TR√àS facile)
        2. Si 100% correct ‚Üí 3 questions niveau 2
        3. Si toujours 100% ‚Üí retour normal

        Args:
            reason: "fatigue" ou "overload"
        """
        if reason == "overload":
            state["recovery_questions_remaining"] = 5  # Plus de r√©cup√©ration
        else:
            state["recovery_questions_remaining"] = 3  # R√©cup√©ration l√©g√®re

        state["recovery_mode"] = True
        logger.info(f"üîÑ Mode r√©cup√©ration activ√©: {state['recovery_questions_remaining']} questions faciles")

    def _update_recovery_mode(self, state: Dict, is_correct: bool, difficulty: int):
        """
        Met √† jour le mode r√©cup√©ration apr√®s une r√©ponse .

        Si l'utilisateur r√©ussit les questions faciles ‚Üí sort progressivement
        Sinon ‚Üí reste en mode r√©cup√©ration plus longtemps
        """
        if not state.get("recovery_mode", False):
            return

        remaining = state.get("recovery_questions_remaining", 0)

        if is_correct and difficulty == 1:
            # Question facile r√©ussie ‚Üí d√©cr√©menter
            state["recovery_questions_remaining"] = max(0, remaining - 1)

            if state["recovery_questions_remaining"] == 0:
                # Fin de r√©cup√©ration
                state["recovery_mode"] = False
                logger.info("‚úÖ Mode r√©cup√©ration termin√© - Retour normal")
        else:
            # Erreur en r√©cup√©ration ‚Üí prolonger l√©g√®rement
            if not is_correct:
                state["recovery_questions_remaining"] = min(remaining + 1, 5)


    # =========================================================================
    # USER PERFORMANCE LEVEL (v4.2)
    # =========================================================================

    def _get_user_performance_level(self, state: Dict) -> float:
        """
        Calcule le niveau de performance historique de l'utilisateur (0-1).

        Bas√© sur:
        - Accuracy sur les 20 derni√®res r√©ponses
        - Ratio de r√©cup√©rations (recovery modes)
        - Streak moyen

        Retourne:
        - 0.4 = utilisateur en difficult√© (struggling)
        - 0.5 = utilisateur moyen
        - 0.7 = utilisateur performant
        """
        responses = state.get("responses", [])

        if len(responses) < 5:
            return 0.5  # Pas assez de donn√©es, d√©faut moyen

        # Accuracy sur les 20 derni√®res
        recent = responses[-20:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / len(recent)

        # Compter les recovery modes (s√©quences de 3+ erreurs)
        recovery_count = 0
        consecutive = 0
        for r in responses[-50:]:
            if not r.get("is_correct", True):
                consecutive += 1
                if consecutive == 3:
                    recovery_count += 1
            else:
                consecutive = 0

        # P√©nalit√© pour beaucoup de recovery modes
        recovery_penalty = min(0.2, recovery_count * 0.05)

        # Score final
        performance = accuracy - recovery_penalty
        return max(0.3, min(0.8, performance))

    def _is_early_game(self, state: Dict) -> bool:
        """
        D√©termine si l'utilisateur est en "early game" (d√©but d'apprentissage).

        Les 7 premiers jours sont critiques - on doit √©viter la spirale n√©gative.
        """
        responses = state.get("responses", [])

        # Moins de 50 r√©ponses = early game
        if len(responses) < 50:
            return True

        # V√©rifier la date de premi√®re r√©ponse
        if responses:
            first_response = responses[0].get("timestamp")
            if first_response:
                days_since_start = (datetime.now() - first_response).days
                return days_since_start <= 7

        return False

    # =========================================================================
    # AI TUTOR - Tracking des patterns d'erreurs
    # =========================================================================

    def _update_ai_tutor_state(self, state: Dict, topic_id: str, is_correct: bool):
        """Met √† jour l'√©tat AI Tutor apr√®s une r√©ponse."""
        if "ai_tutor_state" not in state:
            state["ai_tutor_state"] = {
                "session_count": 1,
                "confusion_pairs": {},
                "motivation_history": [],
                "last_topics": [],
            }

        ai_state = state["ai_tutor_state"]

        # Tracker le topic
        last_topics = ai_state.get("last_topics", [])
        last_topics.append(topic_id)
        if len(last_topics) > 20:
            last_topics.pop(0)
        ai_state["last_topics"] = last_topics

        # D√©tecter confusions (erreur apr√®s changement de topic)
        if not is_correct and len(last_topics) >= 2:
            prev_topic = last_topics[-2]
            if prev_topic != topic_id:
                pair = tuple(sorted([prev_topic, topic_id]))
                confusion_pairs = ai_state.get("confusion_pairs", {})
                pair_key = f"{pair[0]}|{pair[1]}"
                confusion_pairs[pair_key] = confusion_pairs.get(pair_key, 0) + 1
                ai_state["confusion_pairs"] = confusion_pairs

    def _increment_session_count(self, state: Dict):
        """Incr√©mente le compteur de sessions (appel√© au d√©but de chaque session)."""
        if "ai_tutor_state" not in state:
            state["ai_tutor_state"] = {}
        state["ai_tutor_state"]["session_count"] = state["ai_tutor_state"].get("session_count", 0) + 1

    # =========================================================================
    # MODULE 5: INTERLEAVING
    # =========================================================================

    def _should_interleave(self, state: Dict, current_topic: str) -> bool:
        """
        D√©termine si on devrait sugg√©rer de changer de sujet.

        Interleaving = m√©langer les sujets au lieu de bloquer.
        +43% de r√©tention selon Rohrer & Taylor (2007).
        """
        # Compter les questions cons√©cutives sur le m√™me topic
        consecutive = 0
        for r in reversed(state["responses"][-10:]):
            if r.get("topic_id") == current_topic:
                consecutive += 1
            else:
                break

        # Sugg√©rer interleaving apr√®s 3-5 questions sur le m√™me sujet
        return consecutive >= 4

    # =========================================================================
    # API PRINCIPALE
    # =========================================================================

    def get_next_question(
        self,
        user_id: str,
        topic_id: str,
        current_mastery: int
    ) -> QuestionParams:
        """
        Calcule les param√®tres optimaux pour la prochaine question.

        Args:
            user_id: ID utilisateur
            topic_id: ID du topic
            current_mastery: Ma√Ætrise actuelle (0-100)

        Returns:
            QuestionParams avec difficult√© optimale et m√©tadonn√©es
        """
        state = self._get_user_state(user_id)

        # Mettre √† jour la ma√Ætrise
        state["mastery"][topic_id] = current_mastery

        # Initialiser session_start_time si premi√®re question
        if "session_start_time" not in state or state["session_start_time"] is None:
            state["session_start_time"] = datetime.now()

        # =====================================================================
        # √âVALUATION UNIFI√âE DE L'√âTAT UTILISATEUR
        # =====================================================================
        user_state = self._assess_user_state(state)

        # Activer recovery mode si n√©cessaire
        if user_state.recovery_mode and not state.get("recovery_mode", False):
            reason = "overload" if user_state.cognitive_load in ["high", "overload"] else "fatigue"
            self._initiate_recovery_mode(state, reason)

        # =====================================================================
        # COLLECTE DES DONN√âES POUR CALCUL DIFFICULT√â
        # =====================================================================

        # FSRS
        card = self._get_fsrs_card(state, topic_id)
        retrievability = self._get_retrievability(state, topic_id)

        # Stats r√©centes
        recent = state["responses"][-10:]
        recent_accuracy = sum(1 for r in recent if r.get("is_correct", False)) / max(1, len(recent))

        # Niveau de performance utilisateur
        user_performance = self._get_user_performance_level(state)

        # =====================================================================
        # HI√âRARCHIE DE D√âCISION DIFFICULT√â (Priorit√©s claires)
        # =====================================================================

        # PRIORIT√â 1: Mode r√©cup√©ration (post-fatigue/surcharge)
        if state.get("recovery_mode", False):
            difficulty = 1
            logger.debug(f"üîÑ Recovery mode: {state.get('recovery_questions_remaining', 0)} questions remaining")

        # PRIORIT√â 2: Quick wins (early game boost)
        elif quick_wins := state.get("quick_wins_remaining", 0):
            difficulty = 1
            state["quick_wins_remaining"] = quick_wins - 1
            logger.debug(f"‚ö° Quick win mode: {quick_wins - 1} remaining")

        # PRIORIT√â 3: Flow state (maintenir l'immersion)
        elif user_state.flow_state == "in_flow" and len(state["responses"]) > 0:
            last_difficulty = state["responses"][-1].get("difficulty", 3)
            # Maintenir difficult√© si appropri√©e (2-4)
            if 2 <= last_difficulty <= 4:
                difficulty = last_difficulty
                logger.debug(f"üåä Flow state - maintaining difficulty {difficulty}")
            else:
                # Sinon, calcul normal
                difficulty = self._calculate_optimal_difficulty(
                    mastery=current_mastery,
                    retrievability=retrievability,
                    cognitive_load=user_state.cognitive_load,
                    recent_accuracy=recent_accuracy,
                    streak=state["streak"],
                    user_performance_level=user_performance
                )

        # PRIORIT√â 4: Calcul optimal standard
        else:
            difficulty = self._calculate_optimal_difficulty(
                mastery=current_mastery,
                retrievability=retrievability,
                cognitive_load=user_state.cognitive_load,
                recent_accuracy=recent_accuracy,
                streak=state["streak"],
                user_performance_level=user_performance
            )

        # =====================================================================
        # CONTRAINTES FINALES
        # =====================================================================

        # Early game protection (nouveaux utilisateurs struggling)
        if self._is_early_game(state) and user_performance < 0.5:
            difficulty = min(2, difficulty)
            logger.debug(f"üõ°Ô∏è Early game protection: capped at level 2")

        # Interleaving
        interleave = self._should_interleave(state, topic_id)

        return QuestionParams(
            difficulty=difficulty,
            difficulty_name=self.DIFFICULTY_LEVELS[difficulty]["name"],
            topic_id=topic_id,
            fsrs_interval=card.stability,
            retrievability=retrievability,
            cognitive_load=user_state.cognitive_load,
            should_take_break=user_state.should_pause,
            interleave_suggested=interleave
        )

    def process_answer(
        self,
        user_id: str,
        topic_id: str,
        is_correct: bool,
        response_time: float,
        difficulty: int
    ) -> AnswerResult:
        """
        Traite une r√©ponse et met √† jour tous les modules.

        Args:
            user_id: ID utilisateur
            topic_id: ID topic
            is_correct: R√©ponse correcte?
            response_time: Temps de r√©ponse (secondes)
            difficulty: Niveau de difficult√© (1-5)

        Returns:
            AnswerResult avec feedback et mises √† jour
        """
        state = self._get_user_state(user_id)
        difficulty = max(1, min(5, difficulty))  # Clamp 1-5

        # 1. Cognitive Load - enregistrer la r√©ponse
        diff_str = {1: "easy", 2: "easy", 3: "medium", 4: "hard", 5: "hard"}[difficulty]
        state["cognitive_detector"].add_response(
            response_time=int(response_time),
            is_correct=is_correct,
            difficulty=diff_str
        )

        # 2. FSRS - mettre √† jour
        new_card, interval = self._update_fsrs(state, topic_id, is_correct, response_time)

        # 3. Streak
        if is_correct:
            state["streak"] = max(0, state["streak"]) + 1
        else:
            state["streak"] = min(0, state["streak"]) - 1

        # 4. Calculer changement de ma√Ætrise (OPTIMIS√â: progression plus rapide)
        # Multiplicateurs augment√©s pour toutes les difficult√©s
        level_multiplier = {1: 1.2, 2: 1.1, 3: 1.2, 4: 1.3, 5: 1.5}[difficulty]

        current = state["mastery"].get(topic_id, 0)

        if is_correct:
            # Gains de base (OPTIMIS√â pour atteindre 80% mastery en 60 jours)
            # Objectif: ~8% par jour pour √©l√®ve moyen = 80% en 10-12 jours
            base_gain = 5  # Augment√© de 3 √† 5 pour progression plus rapide
            if response_time < 10:
                base_gain += 2  # Bonus r√©ponse rapide augment√© (√©tait +1)

            mastery_change = int(base_gain * level_multiplier)

            # BONUS renforc√© pour d√©butants
            if current < 20:
                mastery_change = int(mastery_change * 1.5)  # +50% au d√©but (√©tait 1.2)
            elif current < 35:
                mastery_change = int(mastery_change * 1.3)  # +30% (√©tait 1.1)

            # Rendements d√©croissants ADOUCIS (moins punitifs)
            # Permet d'atteindre 80% plus facilement
            if current >= 85:
                mastery_change = int(mastery_change * 0.5)  # Divis√© par 2 (√©tait √∑5)
            elif current >= 75:
                mastery_change = int(mastery_change * 0.6)  # 60% (√©tait √∑4)
            elif current >= 65:
                mastery_change = int(mastery_change * 0.75)  # 75% (√©tait √∑3)
            elif current >= 50:
                mastery_change = int(mastery_change * 0.85)  # 85% (√©tait √∑2)
            # Pas de p√©nalit√© avant 50% (√©tait 45%)
        else:
            # Pertes ajust√©es
            base_loss = -2
            if difficulty <= 2:
                base_loss = -3  # Erreur sur facile = perte mod√©r√©e
            elif difficulty >= 4:
                base_loss = -1  # Erreur sur difficile = pardonn√©

            mastery_change = int(base_loss * level_multiplier)

            # Protection pour d√©butants (mais pas totale)
            if current < 20:
                mastery_change = max(-1, mastery_change)  # Petite perte
            elif current < 35:
                mastery_change = max(-2, mastery_change)

            # STRUGGLING USER PROTECTION: Limit mastery loss during bad streaks
            # If already in a bad streak, don't punish further
            if state["streak"] <= -3:
                mastery_change = max(-1, mastery_change)  # Max 1 point loss

        # 5. XP
        xp_earned = self.DIFFICULTY_LEVELS[difficulty]["xp"] if is_correct else 0
        if is_correct and state["streak"] >= 3:
            xp_earned = int(xp_earned * 1.2)  # Bonus streak

        # 6. Enregistrer la r√©ponse
        state["responses"].append({
            "topic_id": topic_id,
            "is_correct": is_correct,
            "response_time": response_time,
            "difficulty": difficulty,
            "timestamp": datetime.now()
        })
        state["last_topic"] = topic_id

        # 6.1 AI Tutor v2.0: Mettre √† jour l'√©tat IA
        self._update_ai_tutor_state(state, topic_id, is_correct)

        # Mettre √† jour ma√Ætrise
        # Cap at 95% - reaching 100% should require sustained mastery over time
        # This keeps experts engaged and prevents "completion" feeling
        MASTERY_CAP = 95
        current = state["mastery"].get(topic_id, 0)
        new_mastery = max(0, min(MASTERY_CAP, current + mastery_change))

        # OPTIMISATION v4.4: Bonus de maintenance pour r√©tention long terme
        # Quand on r√©vise un skill d√©j√† ma√Ætris√© (80%+) et qu'on r√©ussit,
        # on donne un petit bonus pour r√©compenser la r√©vision et maintenir la m√©moire
        if is_correct and current >= 80 and new_mastery < MASTERY_CAP:
            # Bonus de maintenance: +1 point pour r√©visions r√©ussies sur skills ma√Ætris√©s
            # Cela encourage la r√©vision espac√©e (FSRS) et maintient la r√©tention
            maintenance_bonus = 1
            new_mastery = min(MASTERY_CAP, new_mastery + maintenance_bonus)

        state["mastery"][topic_id] = new_mastery

        # 7. Stats et feedback
        recent = state["responses"][-10:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / max(1, len(recent))

        # Utiliser UserState unifi√©
        user_state = self._assess_user_state(state)
        should_break = user_state.should_pause
        should_reduce = user_state.cognitive_load in ["high", "overload"] or accuracy < 0.5

        # RECOVERY MODE v4.2: Enhanced support with Quick Wins
        # Track consecutive errors for recovery mode activation
        consecutive_errors = 0
        for r in reversed(state["responses"][-5:]):
            if not r.get("is_correct", True):
                consecutive_errors += 1
            else:
                break

        in_recovery_mode = consecutive_errors >= 3 or (accuracy < 0.4 and len(recent) >= 5)

        # QUICK WINS: Quand l'utilisateur est en difficult√©, on lui donne
        # des questions tr√®s faciles pour reconstruire sa confiance
        # Le nombre d√©pend de sa performance historique
        if in_recovery_mode:
            user_perf = self._get_user_performance_level(state)
            state["quick_wins_remaining"] = 5 if user_perf < 0.5 else 3
            state["streak"] = 0  # Reset streak pour repartir √† z√©ro

        # FEEDBACK UNIFI√â (√âmotionnel + Celebrations fusionn√©s)
        emotional_state = self._detect_emotional_state(state, is_correct, consecutive_errors)

        # Feedback with enhanced support for struggling users
        if should_break:
            feedback = "Pause recommand√©e - charge cognitive √©lev√©e"
        elif in_recovery_mode:
            # Struggling user gets encouraging, actionable feedback
            recovery_messages = [
                "C'est normal de faire des erreurs, c'est comme √ßa qu'on apprend!",
                "On va y aller doucement - des questions plus simples arrivent",
                "Prends ton temps, chaque question est une opportunit√©",
                "Tu progresses m√™me quand tu te trompes - continue!",
            ]
            import random
            feedback = random.choice(recovery_messages)
            should_reduce = True  # Force difficulty reduction
        else:
            # Utiliser le feedback unifi√© (√©motionnel + celebrations)
            feedback = self._generate_feedback(emotional_state, is_correct, state["streak"], mastery_change, state)

        # 8. Accumuler XP total
        state["total_xp"] = state.get("total_xp", 0) + xp_earned

        # =========================================================================
        # R√âCUP√âRATION PROGRESSIVE (update recovery mode state)
        # =========================================================================

        self._update_recovery_mode(state, is_correct, difficulty)

        # =========================================================================
        # STREAK PROTECTION + MILESTONES + CELEBRATIONS + DECAY WARNINGS
        # =========================================================================

        # Check streak and apply protection if needed
        streak_message, streak_protected = self._check_streak_and_update(state)
        if streak_message:
            feedback = f"{feedback} | {streak_message}"

        # Update question counter for milestones
        state["total_questions_answered"] = state.get("total_questions_answered", 0) + 1

        # Update skills mastered count (80%+ = mastered)
        skills_at_80 = sum(1 for m in state["mastery"].values() if m >= 80)
        state["skills_mastered"] = skills_at_80

        # Check milestones and add to feedback
        milestone_messages = self._check_milestones(state)
        if milestone_messages:
            for msg in milestone_messages:
                feedback = f"{feedback} | {msg}"


        # Detect mastery decay (every 10 questions)
        decay_warnings = []
        if state["total_questions_answered"] % 10 == 0:
            decay_warnings = self._detect_mastery_decay(state)

        # =========================================================================

        # 9. Auto-save en DB (toutes les 5 r√©ponses pour √©viter trop d'I/O)
        if len(state["responses"]) % 5 == 0:
            self.save_state(user_id)

        return AnswerResult(
            mastery_change=mastery_change,
            xp_earned=xp_earned,
            next_review_days=interval,
            accuracy_recent=accuracy,
            should_reduce_difficulty=should_reduce,
            should_take_break=should_break,
            feedback=feedback,
            # New fields
            streak_protected=streak_protected,
            decay_warnings=decay_warnings
        )

    def get_user_stats(self, user_id: str) -> Dict[str, Any]:
        """R√©cup√®re les statistiques d'un utilisateur"""
        state = self._get_user_state(user_id)

        # FSRS stats
        fsrs_stats = {}
        for topic_id, card in state["fsrs_cards"].items():
            fsrs_stats[topic_id] = {
                "stability": card.stability,
                "reps": card.reps,
                "retrievability": self._get_retrievability(state, topic_id)
            }

        # Recent performance
        recent = state["responses"][-20:]
        accuracy = sum(1 for r in recent if r.get("is_correct", False)) / max(1, len(recent))

        user_state = self._assess_user_state(state)
        cognitive_load = user_state.cognitive_load

        return {
            "mastery": state["mastery"],
            "fsrs": fsrs_stats,
            "streak": state["streak"],
            "recent_accuracy": accuracy,
            "cognitive_load": cognitive_load,
            "total_responses": len(state["responses"]),
            "total_xp": state.get("total_xp", 0)
        }

    def reset_session(self, user_id: str, save: bool = True):
        """Reset pour une nouvelle session (sauvegarde avant reset)"""
        if save:
            self.save_state(user_id)

        state = self._get_user_state(user_id)
        state["cognitive_detector"] = CognitiveLoadDetector()
        state["streak"] = 0
        state["responses"] = []  # Reset r√©ponses de session

        # AI Tutor v2.0: Incr√©menter le compteur de sessions
        self._increment_session_count(state)

        logger.info(f"Session reset for {user_id}")

    def get_engine_info(self) -> Dict[str, Any]:
        """Informations sur le moteur"""
        return {
            "version": "4.8 LEAN",
            "modules": 5,
            "features": [
                "DB Persistence",
                "Auto-save",
                "Auto-load",
                "Quick Wins (recovery mode)",
                "Early Game Protection",
                "User Performance Level",
                "AI Tutor v2.0 - M√©moire cross-session",
                "AI Tutor v2.0 - D√©tection patterns d'erreurs",
                "AI Tutor v2.0 - Motivation adaptative",
                "AI Tutor v2.0 - Pr√©diction de difficult√©",
                "AI Tutor v2.0 - Micro-le√ßons cibl√©es",
            ],
            "modules_list": [
                {"name": "FSRS", "research": "Pimsleur (moderne)", "benefit": "Timing optimal des r√©visions"},
                {"name": "Testing Effect", "research": "Dunlosky (2013)", "benefit": "Quiz actif > relecture"},
                {"name": "Adaptive Difficulty", "research": "Vygotsky, Bjork", "benefit": "Zone optimale"},
                {"name": "Cognitive Load", "research": "Sweller (1988)", "benefit": "D√©tection fatigue"},
                {"name": "Interleaving", "research": "Rohrer (2007)", "benefit": "+43% discrimination"},
                {"name": "AI Tutor v2.0", "research": "Simulation NewMars 2024", "benefit": "100% succ√®s tous profils"},
            ],
            "removed_modules": [
                "Forgetting Curve (doublon FSRS)",
                "Emotional Encoding (artificiel)",
                "Dual Coding (pas de vraies images)",
                "Chunking (contenu d√©j√† d√©coup√©)",
                "Elaborative (GPT fait d√©j√†)",
                "Pre-sleep (impr√©cis)",
                "Confidence Tracking (gens mentent)",
                "Transfer Learning (peu de gain)",
                "Variation Practice (doublon)"
            ],
            "philosophy": "Less is more. 5 modules solides > 16 modules dilu√©s."
        }

    def get_all_users(self) -> List[str]:
        """R√©cup√®re la liste de tous les utilisateurs en DB"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()
            cursor.execute("SELECT user_id FROM lean_user_states")
            users = [row[0] for row in cursor.fetchall()]
            conn.close()
            return users
        except Exception as e:
            logger.error(f"Erreur get_all_users: {e}")
            return []

    # =========================================================================
    # SKILL-AWARE DIFFICULTY (Connexion SkillBridge)
    # =========================================================================

    def get_skill_adjusted_difficulty(
        self,
        user_id: str,
        topic_id: str,
        mastery: int,
        task_context: Optional[Dict[str, Any]] = None
    ) -> Dict[str, Any]:
        """
        Calcule la difficult√© en tenant compte du skill graph.

        Combine:
        1. La difficult√© standard du learning engine
        2. La distance de comp√©tence si une t√¢che est fournie

        Args:
            user_id: ID utilisateur
            topic_id: ID du topic
            mastery: Ma√Ætrise actuelle (0-100)
            task_context: T√¢che optionnelle pour calcul de distance

        Returns:
            Dict avec difficulty ajust√©e et m√©tadonn√©es
        """
        # 1. Calcul standard
        params = self.get_next_question(user_id, topic_id, mastery)
        base_difficulty = params.difficulty

        # 2. Si pas de contexte de t√¢che, retourner le calcul standard
        if not task_context:
            return {
                "difficulty": base_difficulty,
                "difficulty_name": params.difficulty_name,
                "source": "learning_engine",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": 0
            }

        # 3. Calculer la distance de skill si possible
        try:
            from services.skill_bridge import get_skill_bridge
            bridge = get_skill_bridge()
            distance = bridge.calculate_task_distance(user_id, task_context)

            # Ajustement bas√© sur la distance
            skill_adjustment = 0
            if distance.total_distance >= 0.6:
                skill_adjustment = -2  # Trop dur, r√©duire
            elif distance.total_distance >= 0.4:
                skill_adjustment = -1  # Difficile, r√©duire l√©g√®rement
            elif distance.total_distance < 0.2:
                skill_adjustment = 1   # Trop facile, augmenter

            # Appliquer l'ajustement
            adjusted_difficulty = max(1, min(5, base_difficulty + skill_adjustment))

            return {
                "difficulty": adjusted_difficulty,
                "difficulty_name": self.DIFFICULTY_LEVELS[adjusted_difficulty]["name"],
                "source": "learning_engine + skill_bridge",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": skill_adjustment,
                "task_distance": distance.total_distance,
                "is_appropriate": distance.is_appropriate,
                "missing_prerequisites": distance.missing_prerequisites,
                "recommendation": distance.recommendation
            }

        except ImportError:
            logger.debug("SkillBridge not available, using standard difficulty")
            return {
                "difficulty": base_difficulty,
                "difficulty_name": params.difficulty_name,
                "source": "learning_engine",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": 0
            }
        except Exception as e:
            logger.warning(f"Error calculating skill distance: {e}")
            return {
                "difficulty": base_difficulty,
                "difficulty_name": params.difficulty_name,
                "source": "learning_engine (skill error)",
                "cognitive_load": params.cognitive_load,
                "retrievability": params.retrievability,
                "skill_adjustment": 0,
                "error": str(e)
            }

    def map_effort_to_difficulty(self, effort: str) -> int:
        """
        Mappe l'effort d'une t√¢che (XS/S/M/L) √† un niveau de difficult√© (1-5).

        Utilis√© pour aligner les t√¢ches de projet avec le syst√®me de difficult√©.
        """
        mapping = {
            "XS": 1,  # Tr√®s facile
            "S": 2,   # Facile
            "M": 3,   # Moyen
            "L": 4,   # Difficile
        }
        return mapping.get(effort, 3)

    def difficulty_to_effort(self, difficulty: int) -> str:
        """
        Mappe un niveau de difficult√© (1-5) √† un effort de t√¢che (XS/S/M/L).

        Inverse de map_effort_to_difficulty.
        """
        if difficulty <= 1:
            return "XS"
        elif difficulty == 2:
            return "S"
        elif difficulty == 3:
            return "M"
        else:
            return "L"


# Instance globale
lean_engine = LeanLearningEngine()
